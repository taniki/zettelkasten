# The Book of Why

![rw-book-cover](https://images-na.ssl-images-amazon.com/images/I/41QP0tzyFBL._SL200_.jpg)

## Metadata
- Author: [[Judea Pearl and Dana Mackenzie]]
- Full Title: The Book of Why
- Category: books
- Document Tags: #causality #statistics

## Highlights
- Causal inference is all about taking this question seriously. It posits that the human brain is the most advanced tool ever devised for managing causes and effects. ([Location 87](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=87))
- Ironically, the need for a theory of causation began to surface at the same time that statistics came into being. In fact, modern statistics hatched from the causal questions that Galton and Pearson asked about heredity and their ingenious attempts to answer them using cross-generational data. Unfortunately, they failed in this endeavor, and rather than pause to ask why, they declared those questions off limits and turned to developing a thriving, causality-free enterprise called statistics. ([Location 139](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=139))
- It tells us that correlation is not causation, but it does not tell us what causation is. ([Location 149](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=149))
- We live in an era that presumes Big Data to be the solution to all our problems. Courses in “data science” are proliferating in our universities, and jobs for “data scientists” are lucrative in the companies that participate in the “data economy.” But I hope with this book to convince you that data are profoundly dumb. Data can tell you that the people who took a medicine recovered faster than those who did not take it, but they can’t tell you why. ([Location 158](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=158))
    - Tags: [[favorite]] 
- I dare to call it the Causal Revolution, a scientific shakeup that embraces rather than denies our innate cognitive gift of understanding cause and effect. ([Location 172](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=172))
- The calculus of causation consists of two languages: causal diagrams, to express what we know, and a symbolic language, resembling algebra, to express what we want to know. ([Location 177](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=177))
    - Tags: [[favorite]] 
- The do-operator signifies that we are dealing with an intervention rather than a passive observation; classical statistics has nothing remotely similar to this operator. ([Location 193](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=193))
- This confusion between seeing and doing has resulted in a fountain of paradoxes, some of which we will entertain in this book. ([Location 206](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=206))
- One of the crowning achievements of the Causal Revolution has been to explain how to predict the effects of an intervention without actually enacting it. ([Location 211](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=211))
- When the scientific question of interest involves retrospective thinking, we call on another type of expression unique to causal reasoning called a counterfactual. ([Location 213](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=213))
- Counterfactual reasoning, which deals with what-ifs, might strike some readers as unscientific. Indeed, empirical observation can never confirm or refute the answers to such questions. ([Location 221](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=221))
    - Tags: [[favorite]] 
- Counterfactuals are the building blocks of moral behavior as well as scientific thought. The ability to reflect on one’s past actions and envision alternative scenarios is the basis of free will and social responsibility. ([Location 225](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=225))
- First, in the world of AI, you do not really understand a topic until you can teach it to a mechanical robot. That is why you will find me emphasizing and reemphasizing notation, language, vocabulary, and grammar. ([Location 230](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=230))
- I believe that strong AI is an achievable goal and one not to be feared precisely because causality is part of the solution. A causal reasoning module will give machines the ability to reflect on their mistakes, to pinpoint weaknesses in their software, to function as moral entities, and to converse naturally with humans about their own choices and intentions. ([Location 239](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=239))
- The inference engine is a machine that accepts three different kinds of inputs—Assumptions, Queries, and Data—and produces three kinds of outputs. ([Location 249](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=249))
- I especially want to highlight the role of data in the above process. First, notice that we collect data only after we posit the causal model, after we state the scientific query we wish to answer, and after we derive the estimand. This contrasts with the traditional statistical approach, mentioned above, which does not even have a causal model. ([Location 316](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=316))
- That’s all that a deep-learning program can do: fit a function to data. ([Location 341](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=341))
    - Tags: [[favorite]] 
- Millions of lives were lost or shortened because scientists did not have an adequate language or methodology for answering causal questions. ([Location 369](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=369))
- They were canaries in the coal mine that should have alerted scientists to the fact that human intuition is grounded in causal, not statistical, logic. ([Location 374](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=374))
- If I could sum up the message of this book in one pithy phrase, it would be that you are smarter than your data. Data do not understand causes and effects; humans do. ([Location 405](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=405))
- First, very early in our evolution, we humans realized that the world is not made up only of dry facts (what we might call data today); rather, these facts are glued together by an intricate web of cause-effect relationships. Second, causal explanations, not dry facts, make up the bulk of our knowledge, and should be the cornerstone of machine intelligence. Finally, our transition from processors of data to makers of explanations was not gradual; it was a leap that required an external push from an uncommon fruit. This matched perfectly with what I had observed theoretically in the Ladder of Causation: No machine can derive explanations from raw data. It needs a push. ([Location 430](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=430))
- But in roughly the last 50,000 years, something unique happened, which some call the Cognitive Revolution and others (with a touch of irony) call the Great Leap Forward. Humans acquired the ability to modify their environment and their own abilities at a dramatically faster rate. ([Location 437](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=437))
- Evolution has endowed us with the ability to engineer our lives, a gift she has not bestowed on eagles and owls, and the question, again, is “Why?” What computational facility did humans suddenly acquire that eagles did not? ([Location 442](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=442))
- To do this, the thinking entity must possess, consult, and manipulate a mental model of its reality. ([Location 456](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=456))
- In fact, my research on machine learning has taught me that a causal learner must master at least three distinct levels of cognitive ability: seeing, doing, and imagining. ([Location 471](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=471))
- Yet even tool users do not necessarily possess a “theory” of their tool that tells them why it works and what to do when it doesn’t. For that, you need to have achieved a level of understanding that permits imagining. It was primarily this third level that prepared us for further revolutions in agriculture and science and led to a sudden and drastic change in our species’ impact on the planet. ([Location 476](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=476))
- The framework I use to show this goes back to Alan Turing, the pioneer of research in artificial intelligence (AI), who proposed to classify a cognitive system in terms of the queries it can answer. ([Location 480](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=480))
- The first rung of the ladder calls for predictions based on passive observations. ([Location 496](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=496))
- Such questions are the bread and butter of statistics, and they are answered, first and foremost, by collecting and analyzing data. ([Location 498](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=498))
- Good predictions need not have good explanations. ([Location 508](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=508))
- My colleague in computer science at the University of California, Los Angeles, Adnan Darwiche, has titled a position paper “Human-Level Intelligence or Animal-Like Abilities?” which I think frames the question in just the right way. ([Location 518](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=518))
- The goal of strong AI is to produce machines with humanlike intelligence, able to converse with and guide humans. Deep learning has instead given us machines with truly impressive abilities but no intelligence. The difference is profound and lies in the absence of a model of reality. ([Location 519](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=519))
- Deep neural networks have added many more layers to the complexity of the fitted function, but raw data still drives the fitting process. They continue to improve in accuracy as more data are fitted, but they do not benefit from the “super-evolutionary speedup.” ([Location 524](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=524))
- Intervention ranks higher than association because it involves not just seeing but changing what is. Seeing smoke tells us a totally different story about the likelihood of fire than making smoke. We cannot answer questions about interventions with passively collected data, no matter how big the data set or how deep the neural network. ([Location 531](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=531))
- A very direct way to predict the result of an intervention is to experiment with it under carefully controlled conditions. ([Location 542](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=542))
- A sufficiently strong and accurate causal model can allow us to use rung-one (observational) data to answer rung-two (interventional) queries. ([Location 547](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=547))
- Another popular question at the second level of causation is “How?,” which is a cousin of “What if we do …?” ([Location 554](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=554))
- We perform interventions all the time in our daily lives, although we don’t usually use such a fancy term for them. For example, when we take aspirin to cure a headache, we are intervening on one variable (the quantity of aspirin in our body) in order to affect another one (our headache status). ([Location 557](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=557))
- While reasoning about interventions is an important step on the causal ladder, it still does not answer all questions of interest. We might wonder, My headache is gone now, but why? Was it the aspirin I took? The food I ate? The good news I heard? These queries take us to the top rung of the Ladder of Causation, the level of counterfactuals, because to answer them we must go back in time, change history, and ask, “What would have happened if I had not taken the aspirin?” No experiment in the world can deny treatment to an already treated person and compare the two outcomes, so we must import a whole new kind of knowledge. ([Location 560](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=560))
- The rewards of having a causal model that can answer counterfactual questions are immense. Finding out why a blunder occurred allows us to take the right corrective measures in the future. Finding out why a treatment worked on some people and not on others can lead to a new cure for a disease. Answering the question “What if things had been different?” allows us to learn from history and the experience of others, something that no other species appears to do. ([Location 579](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=579))
- As a manifestation of our newfound ability to imagine things that have never existed, the Lion Man is the precursor of every philosophical theory, scientific discovery, and technological innovation, from microscopes to airplanes to computers. Every one of these had to take shape in someone’s imagination before it was realized in the physical world. ([Location 595](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=595))
- The advantage we gained from imagining counterfactuals was the same then as it is today: flexibility, the ability to reflect and improve on past actions, and, perhaps even more significant, our willingness to take responsibility for past and current actions. ([Location 600](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=600))
    - Tags: [[critical thinking]] [[countetfactual]] [[favorite]] 
- While rung one deals with the seen world, and rung two deals with a brave new world that is seeable, rung three deals with a world that cannot be seen (because it contradicts what is seen). To bridge the gap, we need a model of the underlying causal process, sometimes called a “theory” or even (in cases where we are extraordinarily confident) a “law of nature.” In short, we need understanding. ([Location 605](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=605))
- We probably will not succeed in creating humanlike intelligence until we can create childlike intelligence, and a key component of this intelligence is the mastery of causation. ([Location 625](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=625))
- One major contribution of AI to the study of cognition has been the paradigm “Representation first, acquisition second.” Often the quest for a good representation has led to insights into how the knowledge ought to be acquired, be it from data or a programmer. ([Location 639](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=639))
- Humans must have some compact representation of the information needed in their brains, as well as an effective procedure to interpret each question properly and extract the right answer from the stored representation. ([Location 652](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=652))
- If we want our computer to understand causation, we have to teach it how to break the rules. We have to teach it the difference between merely observing an event and making it happen. ([Location 678](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=678))
    - Tags: [[favorite]] 
- Causal reasoning is easy for you because you are human, and you were once a three-year-old, and you had a marvelous three-year-old brain that understood causation better than any animal or computer. ([Location 712](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=712))
- Computers are not good at breaking rules, a skill at which children excel. ([Location 715](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=715))
- For example, there could be many more variables, and they might not be simple binary (true/false) variables. Instead of predicting whether a prisoner is alive or dead, we might want to predict how much the unemployment rate will go up if we raise the minimum wage. This kind of quantitative causal reasoning is generally beyond the power of our intuition. ([Location 717](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=717))
    - Tags: [[favorite]] 
- translate the story into a diagram, listen to the query, perform a surgery that corresponds to the given query (interventional or counterfactual; if the query is associational then no surgery is needed), and use the modified causal model to compute the answer. ([Location 750](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=750))
- Decades’ worth of experience with these kinds of questions has convinced me that, in both a cognitive and a philosophical sense, the idea of causes and effects is much more fundamental than the idea of probability. ([Location 759](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=759))
- Almost without exception, philosophers expressed the sentence “X raises the probability of Y” using conditional probabilities and wrote P(Y | X) > P(Y). This interpretation is wrong, as you surely noticed, because “raises” is a causal concept, connoting a causal influence of X over Y. ([Location 779](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=779))
- Probabilities, as given by expressions like P(Y | X), lie on the first rung of the Ladder of Causation and cannot ever (by themselves) answer queries on the second or third rung. Any attempt to “define” causation in terms of seemingly simpler, first-rung concepts must fail. That is why I have not attempted to define causation anywhere in this book: definitions demand reduction, and reduction demands going to a lower rung. Instead, I have pursued the ultimately more constructive program of explaining how to answer causal queries and what information is needed to answer them. ([Location 785](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=785))
- In 1983, Nancy Cartwright broke this deadlock and enriched the description of the background context with a causal component. She proposed that we should condition on any factor that is “causally relevant” to the effect. ([Location 804](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=804))
- In summary, probabilistic causality has always foundered on the rock of confounding. Every time the adherents of probabilistic causation try to patch up the ship with a new hull, the boat runs into the same rock and springs another leak. Once you misrepresent “probability raising” in the language of conditional probabilities, no amount of probabilistic patching will get you to the next rung of the ladder. As strange as it may sound, the notion of probability raising cannot be expressed in terms of probabilities. ([Location 811](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=811))
- Philosophers have the advantage of standing apart from the hurly-burly of scientific debate and the practical realities of dealing with data. They have been less contaminated than other scientists by the anticausal biases of statistics. They can call upon a tradition of thought about causation that goes back at least to Aristotle, and they can talk about causation without blushing or hiding it behind the label of “association.” ([Location 820](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=820))
- Given that we see certain facts, Bayesian networks can swiftly compute the likelihood that certain other facts are true or false. ([Location 831](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=831))
- Bayesian networks inhabit a world where all questions are reducible to probabilities, or (in the terminology of this chapter) degrees of association between variables; they could not ascend to the second or third rungs of the Ladder of Causation. ([Location 843](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=843))
- First, in 1991, the graph-surgery idea empowered them to handle both observations and interventions. Another twist, in 1994, brought them to the third level and made them capable of handling counterfactuals. ([Location 845](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=845))
- The main point is this: while probabilities encode our beliefs about a static world, causality tells us whether and how probabilities change when the world changes, be it by intervention or by act of imagination. ([Location 847](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=847))
- You can predict the son’s height based on the father’s or the father’s based on the son’s. The situation is completely symmetric. Once again this shows that where regression to the mean is concerned, there is no difference between cause and effect. ([Location 976](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=976))
- The correlation will always reflect the degree of cross predictability between the two variables. Galton’s disciple Karl Pearson later derived a formula for the slope of the (properly rescaled) regression line and called it the correlation coefficient. ([Location 996](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=996))
- That stability, now called the Hardy-Weinberg equilibrium, received a satisfactory mathematical explanation in the work of G. H. Hardy and Wilhelm Weinberg in 1908. ([Location 1034](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=1034))
- It remained to Galton’s disciple, Karl Pearson, to complete the task of expunging causation from statistics. Yet even he was not entirely successful. ([Location 1051](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=1051))
- The mental leap from Galton to Pearson is breathtaking and indeed worthy of a buccaneer. Galton had proved only that one phenomenon—regression to the mean—did not require a causal explanation. Now Pearson was completely removing causation from science. What made him take this leap? ([Location 1067](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=1067))
- Ted Porter, ([Location 1069](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=1069))
- Pearson noticed that it’s relatively easy to find correlations that are just plain silly. For instance, for a fun example postdating Pearson’s time, there is a strong correlation between a nation’s per capita chocolate consumption and its number of Nobel Prize winners. ([Location 1102](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=1102))
- Correlation is supposed to be the goal of scientific understanding. This puts him in an awkward position when he has to explain why one correlation is meaningful and another is “spurious.” ([Location 1107](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=1107))
- Pearson, who, like Galton, was a fanatical collector of data on the human body, had obtained measurements of 806 male skulls and 340 female skulls from the Paris Catacombs (Figure 2.5). ([Location 1117](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=1117))
- This rule sets up a bridge from the deep, hidden world of causation to the surface world of correlations. It was the first bridge ever built between causality and probability, the first crossing of the barrier between rung two and rung one on the Ladder of Causation. Having built this bridge, Wright could travel backward over it, from the correlations measured in the data (rung one) to the hidden causal quantities, d and h (rung two). He did this by solving algebraic equations. ([Location 1188](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=1188))
- One thing the diagram does not show explicitly is the difference between an inbred family and a normal family. In an inbred family there would be a strong correlation between the heredity of the sire and the dam, which Wright indicated with a two-headed arrow between Hʺ and Hʹʹʹ. ([Location 1212](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=1212))
- When you take apart the diagram arrow by arrow in this way, I think you will find that every one of them makes perfect sense. Note also that each arrow is accompanied by a small letter (a, b, c, etc.). These letters, called path coefficients, represent the strength of the causal effects that Wright wanted to solve for. Roughly speaking, a path coefficient represents the amount of variability in the target variable that is accounted for by the source variable. ([Location 1218](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=1218))
- Wright’s paper was a tour de force and deserves to be considered one of the landmark results of twentieth-century biology. ([Location 1232](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=1232))
- Although we don’t need to know every causal relation between the variables of interest and might be able to draw some conclusions with only partial information, Wright makes one point with absolute clarity: you cannot draw causal conclusions without some causal hypotheses. ([Location 1255](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=1255))
- Extracting the nonobvious from the obvious is not circular—it is a scientific triumph and deserves to be hailed as such. ([Location 1261](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=1261))
- in path analysis you draw conclusions about individual causal relationships by examining the diagram as a whole. The entire structure of the diagram may be needed to estimate each individual parameter. ([Location 1343](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=1343))
- Scientists will always prefer routine calculations on data to methods that challenge their scientific knowledge. ([Location 1355](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=1355))
- Causal analysis is emphatically not just about data; in causal analysis we must incorporate some understanding of the process that produces the data, and then we get something that was not in the data to begin with. ([Location 1359](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=1359))
    - Tags: [[favorite]] 
- Neither Karlin nor Wright realized that a general nonlinear theory was just around the corner. ([Location 1398](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=1398))
- Wright understood that he was defending the very essence of the scientific method and the interpretation of data. I would give the same advice today to big-data, model-free enthusiasts. Of course, it is okay to tease out all the information that the data can provide, but let’s ask how far this will get us. ([Location 1413](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=1413))
- topology of the causal processes ([Location 1430](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=1430))
- Where causation is concerned, a grain of wise subjectivity tells us more about the real world than any amount of objectivity. ([Location 1431](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=1431))
- The prototype of Bayesian analysis goes like this: Prior Belief + New Evidence → Revised Belief. ([Location 1435](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=1435))
    - Tags: [[favorite]] 
- Bayesian statistics give us an objective way of combining the observed evidence with our prior knowledge (or subjective belief) to obtain a revised belief and hence a revised prediction of the outcome of the coin’s next toss. Still, what frequentists could not abide was that Bayesians were allowing opinion, in the form of subjective probabilities, to intrude into the pristine kingdom of statistics. Mainstream statisticians were won over only grudgingly, when Bayesian analysis proved a superior tool for a variety of applications, such as weather prediction and tracking enemy submarines. In addition, in many cases it can be proven that the influence of prior beliefs vanishes as the size of the data increases, leaving a single objective conclusion in the end. ([Location 1442](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=1442))
- Two people who believe in two different causal diagrams can analyze the same data and may never come to the same conclusion, regardless of how “big” the data are. This is a terrifying prospect for advocates of scientific objectivity, which explains their refusal to accept the inevitability of relying on subjective causal information. ([Location 1454](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=1454))
- Although induction and deduction go hand in hand, the former is by far the more mysterious. ([Location 1475](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=1475))
- a causal diagram is a Bayesian network in which every arrow signifies a direct causal relation, or at least the possibility of one, in the direction of that arrow. Not all Bayesian networks are causal, and in many applications it does not matter. ([Location 1502](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=1502))
    - Tags: [[favorite]] 
- His paper is remembered and argued about 250 years later, not for its theology but because it shows that you can deduce the probability of a cause from an effect. If we know the cause, it is easy to estimate the probability of the effect, which is a forward probability. ([Location 1533](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=1533))
- In many ways, Bayes’s rule is a distillation of the scientific method. The textbook description of the scientific method goes something like this: (1) formulate a hypothesis, (2) deduce a testable consequence of the hypothesis, (3) perform an experiment and collect evidence, and (4) update your belief in the hypothesis. ([Location 1707](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=1707))
- Probability was also considered at the time but immediately fell into ill repute, since the demands on storage space and processing time became formidable. I entered the arena rather late, in 1982, with an obvious yet radical proposal: instead of reinventing a new uncertainty theory from scratch, let’s keep probability as a guardian of common sense and merely repair its computational deficiencies. More specifically, instead of representing probability in huge tables, as was previously done, let’s represent it with a network of loosely coupled variables. If we only allow each variable to interact with a few neighboring variables, then we might overcome the computational hurdles that had caused other probabilists to stumble. ([Location 1731](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=1731))
- Reading Rumelhart’s paper, I felt convinced that any artificial intelligence would have to model itself on what we know about human neural information processing and that machine reasoning under uncertainty would have to be constructed with a similar message-passing architecture. But what are the messages? This took me quite a few months to figure out. I finally realized that the messages were conditional probabilities in one direction and likelihood ratios in the other. ([Location 1747](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=1747))
- These three junctions—chains, forks, and colliders—are like keyholes through the door that separates the first and second levels of the Ladder of Causation. If we peek through them, we can see the secrets of the causal process that generated the data we observe; each stands for a distinct pattern of causal flow and leaves its mark in the form of conditional dependences and independences in the data. ([Location 1826](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=1826))
- This fundamental connection between causes and probabilities constitutes the main contribution of Bayesian networks to the science of causal inference. ([Location 1833](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=1833))
- One technical advance in the development of Bayesian networks entailed finding ways to leverage sparseness in the network structure to achieve reasonable computation times. ([Location 1899](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=1899))
- The network is integrative, which means that it reacts as a whole to any new information. ([Location 1936](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=1936))
- The transparency of Bayesian networks distinguishes them from most other approaches to machine learning, which tend to produce inscrutable “black boxes.” In a Bayesian network you can follow every step and understand how and why each piece of evidence changed the network’s beliefs. ([Location 1940](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=1940))
- One goal of causal inference is to create a smoother human-machine interface, which might allow the investigators’ intuition to join the belief propagation dance. ([Location 1945](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=1945))
- By any measure, turbo codes have been a staggering success. Before the turbo revolution, 2G cell phones used “soft decoding” (i.e., probabilities) but not belief propagation. 3G cell phones used Berrou’s turbo codes, and 4G phones used Gallager’s turbo-like codes. From the consumer’s viewpoint, this means that your cell phone uses less energy and the battery lasts longer, because coding and decoding are your cell phone’s most energy-intensive processes. Also, better codes mean that you do not have to be as close to a cell tower to get high-quality transmission. In other words, Bayesian networks enabled phone manufacturers to deliver on their promise: more bars in more places. ([Location 1986](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=1986))
- All the probabilistic properties of Bayesian networks (including the junctions we discussed earlier in this chapter) and the belief propagation algorithms that were developed for them remain valid in causal diagrams. They are in fact indispensable for understanding causal inference. ([Location 1995](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=1995))
- Note that if we reverse the order of arrows in the chain, thus obtaining A ← B ← C, the causal reading of the structure will change drastically, but the independence conditions will remain the same. The missing arrow between A and C will still mean that A and C are independent once we know the value of B, as in the original chain. ([Location 2011](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=2011))
- Another convenient way of thinking about the causal model is in terms of hypothetical experiments. Each arrow can be thought of as a statement about the outcome of a hypothetical experiment. ([Location 2020](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=2020))
- On the other hand, a Bayesian network is not equipped to handle a “wiggle,” or to tell the difference between seeing and doing, or indeed to distinguish a fork from a chain. ([Location 2029](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=2029))
- The relationships that were discovered between the graphical structure of the diagram and the data that it represents now permit us to emulate wiggling without physically doing so. Specifically, applying a smart sequence of conditioning operations enables us to predict the effect of actions or interventions without actually conducting an experiment. ([Location 2033](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=2033))
- The questions we raised above, concerning the effect of interventions, including direct and indirect effects, are not part of mainstream statistics, primarily because the field’s founding fathers purged it of the language of cause and effect. ([Location 2059](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=2059))
- Confounding bias occurs when a variable influences both who is selected for the treatment and the outcome of the experiment. ([Location 2121](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=2121))
- Statisticians have been immensely confused about what variables should and should not be controlled for, so the default practice has been to control for everything one can measure. The vast majority of studies conducted in this day and age subscribe to this practice. It is a convenient, simple procedure to follow, but it is both wasteful and ridden with errors. ([Location 2143](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=2143))
- If we have data on a sufficient set of deconfounders, it does not matter if we ignore some or even all of the confounders. ([Location 2159](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=2159))
- Confounding is a causal concept—it belongs on rung two of the Ladder of Causation. ([Location 2163](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=2163))
- There is now an almost universal consensus, at least among epidemiologists, philosophers, and social scientists, that (1) confounding needs and has a causal solution, and (2) causal diagrams provide a complete and systematic way of finding that solution. ([Location 2173](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=2173))
- But Fisher realized that an uncertain answer to the right question is much better than a highly certain answer to the wrong question. If you ask the genie the wrong question, you will never find out what you want to know. If you ask the right question, getting an answer that is occasionally wrong is much less of a problem. ([Location 2261](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=2261))
    - Tags: [[favorite]] 
- The reason for the difficulty is that confounding is not a statistical notion. It stands for the discrepancy between what we want to assess (the causal effect) and what we actually do assess using statistical methods. If you can’t articulate mathematically what you want to assess, you can’t expect to define what constitutes a discrepancy. ([Location 2333](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=2333))
- Let’s take a look at some of the surrogate definitions of confounding. These fall into two main categories, declarative and procedural. A typical (and wrong) declarative definition would be “A confounder is any variable that is correlated with both X and Y.” On the other hand, a procedural definition would attempt to characterize a confounder in terms of a statistical test. ([Location 2347](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=2347))
- They partitioned the population into four types of individuals: doomed, causative, preventive, and immune. ([Location 2406](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=2406))
- Exchangeability simply means that the percentage of people with each kind of sticker (d percent, c percent, p percent, and i percent, respectively) should be the same in both the treatment and control groups. Equality among these proportions guarantees that the outcome would be just the same if we switched the treatments and controls. Otherwise, the treatment and control groups are not alike, and our estimate of the effect of the vaccine will be confounded. Note that the two groups may be different in many ways. They can differ in age, sex, health conditions, and a variety of other characteristics. Only equality among d, c, p, and i determines whether they are exchangeable or not. So exchangeability amounts to equality between two sets of four proportions, a vast reduction in complexity from the alternative of assessing the innumerable factors by which the two groups may differ. ([Location 2412](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=2412))
- M-bias puts a finger on what is wrong with the traditional approach. It is incorrect to call a variable, like B, a confounder merely because it is associated with both X and Y. To reiterate, X and Y are unconfounded if we do not control for B. B only becomes a confounder when you control for it! ([Location 2497](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=2497))
    - Tags: [[favorite]] 
- Nevertheless, the case-control design has some obvious drawbacks. It is retrospective; that means we study people known to have cancer and look backward to discover why. The probability logic is backward too. The data tell us the probability that a cancer patient is a smoker instead of the probability that a smoker will get cancer. It is the latter probability that really matters to a person who wants to know whether he should smoke or not. ([Location 2655](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=2655))
- Fisher’s methods assume that the experimenter begins with no prior knowledge of or opinions about the hypothesis to be tested. They impose ignorance on the scientist, a situation that the denialists eagerly took advantage of. ([Location 2746](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=2746))
- The tension starts because they stand on two different rungs of the Ladder of Causation and is aggravated by the fact that human intuition operates under the logic of causation, while data conform to the logic of probabilities and proportions. Paradoxes arise when we misapply the rules we have learned in one realm to the other. ([Location 2889](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=2889))
- The lesson is quite simple: the way that we obtain information is no less important than the information itself. ([Location 2945](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=2945))
    - Tags: [[favorite]] 
- But causeless correlation violates our common sense. ([Location 2964](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=2964))
- In my opinion, a true resolution of a paradox should explain why we see it as a paradox in the first place. ([Location 2992](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=2992))
    - Tags: [[favorite]] 
- Our brains are not wired to do probability problems, but they are wired to do causal problems. And this causal wiring produces systematic probabilistic mistakes, like optical illusions. ([Location 2997](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=2997))
    - Tags: [[favorite]] 
- Rebutting the adage “Correlation does not imply causation,” Reichenbach posited a much stronger idea: “No correlation without causation.” He meant that a correlation between two variables, X and Y, cannot come about by accident. Either one of the variables causes the other, or a third variable, say Z, precedes and causes them both. ([Location 3031](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=3031))
    - Tags: [[favorite]] 
- A correct version of his principle would read as follows: an action that increases the probability of a certain outcome assuming either that Event C occurred or that Event C did not occur will also increase its probability if we don’t know whether C occurred … provided that the action does not change the probability of C. ([Location 3144](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=3144))
- We should consult the causal structure of the story, not the temporal information. ([Location 3205](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=3205))
- Instead of suppressing the symptoms, we should pay attention to them. Simpson’s paradox alerts us to cases where at least one of the statistical trends (either in the aggregated data, the partitioned data, or both) cannot represent the causal effects. There are, of course, other warning signs of confounding. The aggregated estimate of the causal effect could, for example, be larger than each of the estimates in each of the strata; this likewise should not happen if we have controlled properly for confounders. ([Location 3217](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=3217))
- For the novice climber, the safest routes up the mountain are the back-door adjustment and its various cousins, some going under the rubric of “front-door adjustment” and some under “instrumental variables.” ([Location 3342](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=3342))
- The role that the back-door criterion plays in this procedure is to guarantee that the causal effect in each stratum of the deconfounder is none other than the observed trend in this stratum. So the causal effect can be estimated stratum by stratum from the data. Absent the back-door criterion, researchers have no guarantee that any adjustment is legitimate. ([Location 3355](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=3355))
- Path coefficients are fundamentally different from regression coefficients, although they can often be computed from the latter. ([Location 3406](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=3406))
- The back-door criterion tells us which sets of variables we can use to deconfound our data. The adjustment formula actually does the deconfounding. ([Location 3414](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=3414))
- In fact, one of the major accomplishments of causal diagrams is to make the assumptions transparent so that they can be discussed and debated by experts and policy makers. ([Location 3494](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=3494))
- Now let us return to our central question of when a model can replace an experiment, or when a “do” quantity can be reduced to a “see” quantity. ([Location 3573](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=3573))
- Rule 1 says when we observe a variable W that is irrelevant to Y (possibly conditional on other variables Z), then the probability distribution of Y will not change. ([Location 3584](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=3584))
- In other words, we are saying that after we have controlled for a sufficient deconfounding set, any remaining correlation is a genuine causal effect. ([Location 3598](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=3598))
    - Tags: [[favorite]] 
- The front-door adjustment formula was a delightful surprise and an indication that do-calculus had something important to offer. ([Location 3634](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=3634))
- It tells us that if we cannot find a way to estimate P(Y | do(X)) from Rules 1 to 3, then a solution does not exist. ([Location 3649](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=3649))
- “Try the do-calculus,” ([Location 3694](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=3694))
- Wermuth and Cox, unaware of this method, called their problem “indirect confounding” and published three papers on its analysis (2008, 2014, and 2015). ([Location 3705](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=3705))
- Although the identification of instrumental sets goes beyond do-calculus, it still uses the tools of causal diagrams. ([Location 3961](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=3961))
- Responsibility and blame, regret and credit: these concepts are the currency of a causal mind. ([Location 3988](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=3988))
- This chapter shows how to use observational and experimental data to extract information about counterfactual scenarios. It explains how to represent individual-level causes in the context of a causal diagram, a task that will force us to explain some nuts and bolts of causal diagrams that we have not talked about yet. ([Location 3992](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=3992))
- Whereas regularities can be observed, counterfactuals can only be imagined. ([Location 4081](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=4081))
- It is worth thinking for a moment about why Hume chooses to define causes in terms of counterfactuals, rather than the other way around. Definitions are intended to reduce a more complicated concept to a simpler one. ([Location 4082](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=4082))
- Like Hume, Lewis was evidently impressed by the fact that humans make counterfactual judgments without much ado, swiftly, comfortably, and consistently. We can assign them truth values and probabilities with no less confidence than we do for factual statements. In his view, we do this by envisioning “possible worlds” in which the counterfactual statements are true. ([Location 4095](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=4095))
- Our shared mental models bind us together into communities. ([Location 4114](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=4114))
- Structural models also offer a resolution of a puzzle Lewis kept silent about: How do humans represent “possible worlds” in their minds and compute the closest one, when the number of possibilities is far beyond the capacity of the human brain? Computer scientists call this the “representation problem.” ([Location 4121](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=4121))
- It is not too much of a stretch to think that 40,000 years ago, humans co-opted the machinery in their brain that already existed for pattern recognition and started to use it for causal reasoning. ([Location 4126](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=4126))
- Logic void of representation is metaphysics. Causal diagrams, with their simple rules of following and erasing arrows, must be close to the way that our brains represent counterfactuals. ([Location 4134](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=4134))
- Also, note that the potential outcome, or counterfactual, is defined at the level of an individual, not a population. ([Location 4154](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=4154))
- The diagram encodes the causal story behind the data, according to which Experience listens to Education and Salary listens to both. ([Location 4245](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=4245))
- Here is how we can use a causal diagram to test for (conditional) ignorability. To determine if X is ignorable relative to outcome Y, conditional on a set Z of matching variables, we need only test to see if Z blocks all the back-door paths between X and Y and no member of Z is a descendant of X. ([Location 4373](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=4373))
- A model cast as a causal diagram can easily be tested for compatibility with the data, whereas a model cast in potential outcome language lacks this feature. ([Location 4385](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=4385))
    - Tags: [[favorite]] 
- One other important difference between SEMs and SCMs, besides the middle letter, is that the relationship between causes and effects in an SCM is not necessarily linear. ([Location 4427](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=4427))
- Bias is a slippery statistical notion, which may disappear if you slice the data a different way. Discrimination, as a causal concept, reflects reality and must remain stable. ([Location 4883](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=4883))
- The sure-thing principle, as Leonard Savage originally stated it, pertains to total effects, while this theorem holds for direct effects. The very definition of a direct effect on a global level relies on aggregating direct effects in the subpopulations. ([Location 4910](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=4910))
- The short answer is that this does not work in models that involve interactions (sometimes called moderation). For example, imagine a drug that causes the body to secrete an enzyme that acts as a catalyst: it combines with the drug to cure a disease. The total effect of the drug is, of course, positive. But the direct effect is zero, because if we disable the mediator (for example, by preventing the body from stimulating the enzyme), the drug will not work. The indirect effect is also zero, because if we don’t receive the drug and do artificially get the enzyme, then the disease will not be cured. ([Location 5007](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=5007))
- In 1986, Reuben Baron and David Kenny articulated a set of principles for detecting and evaluating mediation in a system of equations. The essential principles are, first, that the variables are all related by linear equations, which are estimated by fitting them to the data. Second, direct and indirect effects are computed by fitting two equations to the data: one with the mediator included and one with the mediator excluded. Significant change in the coefficients when the mediator is introduced is taken as evidence of mediation. ([Location 5034](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=5034))
- So hardly anyone noticed the grand leap forward involved, the fact that a causal quantity (mediation) was defined and assessed by purely statistical means. ([Location 5046](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=5046))
- Which of these is right? Neither! Both groups of researchers confused the procedure with the meaning. The procedure is mathematical; the meaning is causal. ([Location 5093](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=5093))
    - Tags: [[favorite]] 
- But I was stuck for almost two years on the dilemma I wrote about in the last section: How can I disable the direct effect? ([Location 5153](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=5153))
- This is a philosophical difference between their school and mine. They believe that the legitimacy of causal inference lies in replicating a randomized experiment as closely as possible, on the assumption that this is the only route to the scientific truth. I believe that there may be other routes, which derive their legitimacy from a combination of data and established (or assumed) scientific knowledge. To that end, there may be methods more powerful than a randomized experiment, based on rung-three assumptions, and I do not hesitate to use them. ([Location 5200](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=5200))
    - Tags: [[favorite]] 
- Many people find formulas daunting, seeing them as a way of concealing rather than revealing information. But to a mathematician, or to a person who is adequately trained in the mathematical way of thinking, exactly the reverse is true. A formula reveals everything: it leaves nothing to doubt or ambiguity. When reading a scientific article, I often catch myself jumping from formula to formula, skipping the words altogether. To me, a formula is a baked idea. Words are ideas in the oven. ([Location 5206](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=5206))
- That is the second purpose of a formula. It is a social contract. It puts a frame around an idea and says, “This is something I believe is important. This is something that deserves sharing.” ([Location 5218](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=5218))
    - Tags: [[formalism]] [[mathematics]] [[favorite]] 
- A generation ago, a marine biologist might have spent months doing a census of his or her favorite species. Now the same biologist has immediate access online to millions of data points on fish, eggs, stomach contents, or anything else he or she wants. Instead of just doing a census, the biologist can tell a story. ([Location 5430](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=5430))
- Data interpretation means hypothesizing on how things operate in the real world. ([Location 5445](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=5445))
- It’s easy to understand why some people would see data mining as the finish rather than the first step. It promises a solution using available technology. It saves us, as well as future machines, the work of having to consider and articulate substantive assumptions about how the world operates. ([Location 5452](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=5452))
    - Tags: [[computer]] [[machine learning]] [[favorite]] 
- Suppose we want to know the effect of an online advertisement (X) on the likelihood that a consumer will purchase the product (Y)—say, a surfboard. We have data from studies in five different places: Los Angeles, Boston, San Francisco, Toronto, and Honolulu. Now we want to estimate how effective the advertisement will be in Arkansas. Unfortunately, each population and each study differs slightly. For example, the Los Angeles population is younger than our target population, and the San Francisco population differs in click-through rate. Figure 10.1 shows the unique characteristics of each population and each study. Can we combine the data from these remote and disparate studies to estimate the ad’s effectiveness in Arkansas? Can we do it without taking any data in Arkansas? Or perhaps by measuring merely a small set of variables or conducting a pilot observational study? ([Location 5468](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=5468))
- Elias Bareinboim has managed to do the same thing for the problem of transportability that Ilya Shpitser did for the problem of interventions. He has developed an algorithm that can automatically determine for you whether the effect you are seeking is transportable, using graphical criteria alone. In other words, it can tell you whether the required separation of S from the do-operators can be accomplished or not. ([Location 5505](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=5505))
- Transparency enables effective communication. ([Location 5593](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=5593))
- Like the prisoners in Plato’s famous cave, deep-learning systems explore the shadows on the cave wall and learn to accurately predict their movements. They lack the understanding that the observed shadows are mere projections of three-dimensional objects moving in a three-dimensional space. Strong AI requires this understanding. ([Location 5600](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=5600))
- The methods described for equipping a machine with a symbolic representation of its environment and the capacity to imagine a hypothetical perturbation of that environment can be extended to include the machine itself as part of the environment. No machine can process a complete copy of its own software, but it can have a blueprint summary of its major software components. Other components can then reason about that blueprint and mimic a state of self-awareness. ([Location 5675](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=5675))
- This may even be how our own causal education as infants begins. We may have something like an “intention generator” in our minds, which tells us that we are supposed to take action X = x. But children love to experiment—to defy their parents’, their teachers’, even their own initial intentions—and to do something different, just for fun. Fully aware that we are supposed to do X = x, we playfully do X = xʹ instead. We watch what happens, repeat the process, and keep a record of how good our intention generator is. Finally, when we start to adjust our own software, that is when we begin to take moral responsibility for our actions. This responsibility may be an illusion at the level of neural activation but not at the level of self-awareness software. ([Location 5685](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=5685))
- The first requirement of a moral machine is the ability to reflect on its own actions, which falls under counterfactual analysis. Once we program self-awareness, however limited, empathy and fairness follow, for it is based on the same computational principles, with another agent added to the equation. ([Location 5724](https://readwise.io/to_kindle?action=open&asin=B077YGFJ8N&location=5724))
