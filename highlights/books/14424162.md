# Superforecasting

![rw-book-cover](https://images-na.ssl-images-amazon.com/images/I/51%2BcBe-c2UL._SL200_.jpg)

## Metadata
- Author: [[Philip Tetlock and Dan Gardner]]
- Full Title: Superforecasting
- Category: books

## Highlights
- He was aiming for a PhD in math, but he realized it was beyond his abilities—“I had my nose rubbed in my limitations” is how he puts it—and he dropped out. It wasn’t wasted time, however. Classes in ornithology made Bill an avid bird-watcher, and because Arizona is a great place to see birds, he did fieldwork part-time for scientists, then got a job with the Department of Agriculture and stayed for a while. ([Location 53](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=53))
- What my research had shown was that the average expert had done little better than guessing on many of the political and economic questions I had posed. “Many” does not equal all. It was easiest to beat chance on the shortest-range questions that only required looking one year out, and accuracy fell off the further out experts tried to forecast—approaching the dart-throwing-chimpanzee level three to five years out. That was an important finding. ([Location 109](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=109))
- I believe it is possible to see into the future, at least in some situations and to some extent, and that any intelligent, open-minded, and hardworking person can cultivate the requisite skills. ([Location 122](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=122))
## New highlights added March 30, 2022 at 5:36 AM
- In one of history’s great ironies, scientists today know vastly more than their colleagues a century ago, and possess vastly more data-crunching power, but they are much less confident in the prospects for perfect predictability. ([Location 177](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=177))
- How predictable something is depends on what we are trying to predict, how far into the future, and under what circumstances. ([Location 223](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=223))
- Laws of physics aside, there are no universal constants, so separating the predictable from the unpredictable is difficult work. There’s no way around it. ([Location 232](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=232))
- Big leaps in computing power and continued refinement of forecasting models may nudge the limits a little further into the future but those advances gradually get harder and the payoffs shrink toward zero. How good can it get? No one knows. But knowing the current limits is itself a success. ([Location 239](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=239))
- That’s because the forecast-measure-revise procedure operates only within the rarefied confines of high-tech forecasting, such as the work of macroeconomists at central banks or marketing and financial professionals in big companies or opinion poll analysts like Nate Silver.7 More often forecasts are made and then … nothing. Accuracy is seldom determined after the fact and is almost never done with sufficient regularity and rigor that conclusions can be drawn. The reason? Mostly it’s a demand-side problem: The consumers of forecasting—governments, business, and the public—don’t demand evidence of accuracy. So there is no measurement. Which means no revision. And without revision, there can be no improvement. ([Location 243](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=243))
- “I have been struck by how important measurement is to improving the human condition,” Bill Gates wrote. “You can achieve incredible progress if you set a clear goal and find a measure that will drive progress toward that goal. … This may seem basic, but it is amazing how often it is not done and how hard it is to get right.” ([Location 252](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=252))
- Sometimes forecasts are used to advance political agendas and galvanize action—as activists hope to do when they warn of looming horrors unless we change our ways. ([Location 260](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=260))
- This jumble of goals is seldom acknowledged, which makes it difficult to even start working toward measurement and progress. It’s a messy situation, which doesn’t seem to be getting better. ([Location 264](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=264))
- For scientists, not knowing is exciting. It’s an opportunity to discover; the more that is unknown, the greater the opportunity. ([Location 268](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=268))
- In year 1, GJP beat the official control group by 60%. In year 2, we beat the control group by 78%. GJP also beat its university-affiliated competitors, including the University of Michigan and MIT, by hefty margins, from 30% to 70%, and even outperformed professional intelligence analysts with access to classified data. After two years, GJP was doing so much better than its academic competitors that IARPA dropped the other teams.10 ([Location 296](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=296))
- Foresight isn’t a mysterious gift bestowed at birth. It is the product of particular ways of thinking, of gathering information, of updating beliefs. These habits of thought can be learned and cultivated by any intelligent, thoughtful, determined person. ([Location 303](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=303))
- For centuries, it hobbled progress in medicine. When physicians finally accepted that their experience and perceptions were not reliable means of determining whether a treatment works, they turned to scientific testing—and medicine finally started to make rapid advances. The same revolution needs to happen in forecasting. ([Location 317](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=317))
- As with the experts who had real foresight in my earlier research, what matters most is how the forecaster thinks. I’ll describe this in detail, but broadly speaking, superforecasting demands thinking that is open-minded, careful, curious, and—above all—self-critical. It also demands focus. The kind of thinking that produces superior judgment does not come effortlessly. Only the determined can deliver it reasonably consistently, which is why our analyses have consistently found commitment to self-improvement to be the strongest predictor of performance. ([Location 334](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=334))
- Human thought is beset by psychological pitfalls, a fact that has only become widely recognized in the last decade or two. ([Location 382](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=382))
## New highlights added March 31, 2022 at 11:41 AM
- If patients who were identical in every way were put into two groups, and the groups were treated differently, he wrote, we would know the treatment caused any difference in outcome. It seems simple but is impossible in practice because no two people are exactly alike, not even identical twins, so the experiment will be confounded by the differences among test subjects. The solution lay in statistics: Randomly assigning people to one group or the other would mean whatever differences there are among them should balance out if enough people participated in the experiment. Then we can confidently conclude that the treatment caused any differences in observed outcomes. It isn’t perfect. There is no perfection in our messy world. But it beats wise men stroking their chins. ([Location 465](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=465))
## New highlights added March 31, 2022 at 11:01 PM
- Like everyone else, scientists have intuitions. Indeed, hunches and flashes of insight—the sense that something is true even if you can’t prove it—have been behind countless breakthroughs. The interplay between System 1 and System 2 can be subtle and creative. But scientists are trained to be cautious. They know that no matter how tempting it is to anoint a pet hypothesis as The Truth, alternative explanations must get a hearing. And they must seriously consider the possibility that their initial hunch is wrong. ([Location 609](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=609))
- The key is doubt. Scientists can feel just as strongly as anyone else that they know The Truth. But they know they must set that feeling aside and replace it with finely measured degrees of doubt—doubt that can be reduced (although never to zero) by better evidence from better studies. ([Location 615](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=615))
- Formally, it’s called attribute substitution, but I call it bait and switch: when faced with a hard question, we often surreptitiously replace it with an easy one. ([Location 634](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=634))
- There is nothing mystical about an accurate intuition like the fire commander’s. It’s pattern recognition. With training or experience, people can encode patterns deep in their memories in vast number and intricate detail—such as the estimated fifty thousand to one hundred thousand chess positions that top players have in their repertoire.20 If something doesn’t fit a pattern—like a kitchen fire giving off more heat than a kitchen fire should—a competent expert senses it immediately. ([Location 676](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=676))
## New highlights added April 1, 2022 at 1:03 AM
- Learning the cues is a matter of opportunity and effort. Sometimes learning the cues is easy. “A child does not need thousands of examples to learn to discriminate dogs from cats.” But other patterns are much harder to master, like the estimated ten thousand hours of practice it takes to learn those fifty thousand to one hundred thousand chess patterns. ([Location 689](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=689))
- The tip-of-your-nose perspective can work wonders but it can also go terribly awry, so if you have the time to think before making a big decision, do so—and be prepared to accept that what seems obviously true now may turn out to be false later. ([Location 700](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=700))
- All too often, forecasting in the twenty-first century looks too much like nineteenth-century medicine. There are theories, assertions, and arguments. There are famous figures, as confident as they are well compensated. But there is little experimentation, or anything that could be called science, so we know much less than most people realize. And we pay the price. Although bad forecasting rarely leads as obviously to harm as does bad medicine, it steers us subtly toward bad decisions and all that flows from them—including monetary losses, missed opportunities, unnecessary suffering, even war and death. Happily, physicians now know the cure for all this. It is a tablespoon of doubt. ([Location 713](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=713))
- Bringing the rigor of measurement to forecasting might seem easier to do: collect forecasts, judge their accuracy, add the numbers. That’s it. ([Location 721](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=721))
- The first step in learning what works in forecasting, and what doesn’t, is to judge forecasts, and to do that we can’t make assumptions about what the forecast means. We have to know. There can’t be any ambiguity about whether a forecast is accurate or not and Ballmer’s forecast is ambiguous. ([Location 734](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=734))
- So here are two forecasts of the sort we routinely encounter. They are serious attempts by smart people to grapple with big issues. Their meaning seems clear. When time passes, their accuracy seems obvious. But it’s not. For various reasons, it’s impossible to say these forecasts are right or wrong beyond all dispute. The truth is, the truth is elusive. ([Location 769](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=769))
- In intelligence circles, Sherman Kent is a legend. With a PhD in history, Kent left a faculty position at Yale to join the Research and Analysis Branch of the newly created Coordinator of Information (COI) in 1941. The COI became the Office of Strategic Services (OSS). The OSS became the Central Intelligence Agency (CIA). By the time Kent retired from the CIA in 1967, he had profoundly shaped how the American intelligence community does what it calls intelligence analysis—the methodical examination of the information collected by spies and surveillance to figure out what it means, and what will happen next. The key word in Kent’s work is estimate. As Kent wrote, “estimating is what you do when you do not know.”9 And as Kent emphasized over and over, we never truly know what will happen next. Hence forecasting is all about estimating the likelihood of something happening, which Kent and his colleagues did for many years at the Office of National Estimates—an obscure but extraordinarily influential bureau whose job was to draw on all information available to the CIA, synthesize it, and forecast anything and everything that might help the top officeholders in the US government decide what to do next. Kent and his colleagues were far from perfect. Most notoriously, they published a 1962 estimate that argued the Soviets would not be so foolish as to deploy offensive missiles to Cuba, when, in fact, they already had. But for the most part, their estimates were well regarded because Kent upheld high standards of analytical rigor. ([Location 840](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=840))
## New highlights added April 1, 2022 at 5:53 PM
- People liked clarity and precision in principle but when it came time to make clear and precise forecasts they weren’t so keen on numbers. Some said it felt unnatural or awkward, which it does when you’ve spent a lifetime using vague language, but that’s a weak argument against change. Others expressed an aesthetic revulsion. Language has its own poetry, they felt, and it’s tacky to talk explicitly about numerical odds. ([Location 890](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=890))
- vague thoughts are easily expressed with vague language but when forecasters are forced to translate terms like “serious possibility” into numbers, they have to think carefully about how they are thinking, a process known as metacognition. ([Location 900](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=900))
- Forecasts must have clearly defined terms and timelines. They must use numbers. And one more thing is essential: we must have lots of forecasts. ([Location 939](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=939))
- The many forecasts required for calibration calculations make it impractical to judge forecasts about rare events, and even with common events it means we must be patient data collectors—and cautious data interpreters. ([Location 954](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=954))
- Important as calibration is, it’s not the whole story because “perfect calibration” isn’t what we think of when we imagine perfect forecasting accuracy. Perfection is godlike omniscience. It’s saying “this will happen” and it does, or “this won’t happen” and it doesn’t. The technical term for this is “resolution.” ([Location 958](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=958))
- The math behind this system was developed by Glenn W. Brier in 1950, hence results are called Brier scores. In effect, Brier scores measure the distance between what you forecast and what actually happened. So Brier scores are like golf scores: lower is better. Perfection is 0. A hedged fifty-fifty call, or random guessing in the aggregate, will produce a Brier score of 0.5. A forecast that is wrong to the greatest possible extent—saying there is a 100% chance that something will happen and it doesn’t, every time—scores a disastrous 2.0, as far from The Truth as it is possible to get. ([Location 977](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=977))
- One group tended to organize their thinking around Big Ideas, although they didn’t agree on which Big Ideas were true or false. Some were environmental doomsters (“We’re running out of everything”); others were cornucopian boomsters (“We can find cost-effective substitutes for everything”). Some were socialists (who favored state control of the commanding heights of the economy); others were free-market fundamentalists (who wanted to minimize regulation). As ideologically diverse as they were, they were united by the fact that their thinking was so ideological. They sought to squeeze complex problems into the preferred cause-effect templates and treated what did not fit as irrelevant distractions. Allergic to wishy-washy answers, they kept pushing their analyses to the limit (and then some), using terms like “furthermore” and “moreover” while piling up reasons why they were right and others wrong. As a result, they were unusually confident and likelier to declare things “impossible” or “certain.” Committed to their conclusions, they were reluctant to change their minds even when their predictions clearly failed. They would tell us, “Just wait.” The other group consisted of more pragmatic experts who drew on many analytical tools, with the choice of tool hinging on the particular problem they faced. These experts gathered as much information from as many sources as they could. When thinking, they often shifted mental gears, sprinkling their speech with transition markers such as “however,” “but,” “although,” and “on the other hand.” They talked about possibilities and probabilities, not certainties. And while no one likes to say “I was wrong,” these experts more readily admitted it and changed their minds. ([Location 1037](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1037))
- Foxes beat hedgehogs. And the foxes didn’t just win by acting like chickens, playing it safe with 60% and 70% forecasts where hedgehogs boldly went with 90% and 100%. Foxes beat hedgehogs on both calibration and resolution. Foxes had real foresight. Hedgehogs didn’t. ([Location 1055](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1055))
- How well aggregation works depends on what you are aggregating. Aggregating the judgments of many people who know nothing produces a lot of nothing. Aggregating the judgments of people who know a little is better, and if there are enough of them, it can produce impressive results, but aggregating the judgments of an equal number of people who know lots about lots of different things is most effective because the collective pool of information becomes much bigger. Aggregations of aggregations can also yield impressive results. ([Location 1122](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1122))
- Now look at how foxes approach forecasting. They deploy not one analytical idea but many and seek out information not from one source but many. Then they synthesize it all into a single conclusion. In a word, they aggregate. They may be individuals working alone, but what they do is, in principle, no different from what Galton’s crowd did. They integrate perspectives and the information contained within them. The only real difference is that the process occurs within one skull. ([Location 1131](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1131))
- A fox with the bulging eyes of a dragonfly is an ugly mixed metaphor but it captures a key reason why the foresight of foxes is superior to that of hedgehogs with their green-tinted glasses. Foxes aggregate perspectives. ([Location 1177](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1177))
- No model captures the richness of human nature. Models are supposed to simplify things, which is why even the best are flawed. But they’re necessary. Our minds are full of models. We couldn’t function without them. And we often function pretty well because some of our models are decent approximations of reality. “All models are wrong,” the statistician George Box observed, “but some are useful.” The fox/hedgehog model is a starting point, not the end. ([Location 1213](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1213))
- In 2006 the Intelligence Advanced Research Projects Activity (IARPA) was created. Its mission is to fund cutting-edge research with the potential to make the intelligence community smarter and more effective. ([Location 1293](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1293))
- In 2008 the Office of the Director of National Intelligence—which sits atop the entire network of sixteen intelligence agencies—asked the National Research Council to form a committee. The task was to synthesize research on good judgment and help the IC put that research to good use. By Washington’s standards, it was a bold (or rash) thing to do. It’s not every day that a bureaucracy pays one of the world’s most respected scientific institutions to produce an objective report that might conclude that the bureaucracy is clueless. ([Location 1297](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1297))
- Even the $50 billion question—How accurate are the forecasts of intelligence analysts?—can’t be answered. Of course, some think they know. Senior officials may claim that the IC is right 80% or 90% of the time. But these are just guesses. Like nineteenth-century physicians who were sure that their treatments cured patients 80% or 90% of the time, they may be right, or close to right, or very wrong. Absent accuracy metrics, there is no meaningful way to hold intelligence analysts accountable for accuracy. ([Location 1312](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1312))
- IARPA’s plan was to create tournament-style incentives for top researchers to generate accurate probability estimates for Goldilocks-zone questions. ([Location 1345](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1345))
## New highlights added April 5, 2022 at 9:09 AM
- Thanks to IARPA, we now know a few hundred ordinary people and some simple math can not only compete with professionals supported by a multibillion-dollar apparatus but also beat them. ([Location 1381](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1381))
- The psychologist Ellen Langer has shown how poorly we grasp randomness in a series of experiments. ([Location 1464](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1464))
- Are superforecasters better simply because they are more knowledgeable and intelligent than others? That would be flattering for them but deflating for the rest of us. Knowledge is something we can all increase, but only slowly. People who haven’t stayed mentally active have little hope of catching up to lifelong learners. Intelligence feels like an even more daunting obstacle. ([Location 1600](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1600))
- Ultimately, it’s not the crunching power that counts. It’s how you use it. ([Location 1645](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1645))
- What Fermi understood is that by breaking down the question, we can better separate the knowable and the unknowable. So guessing—pulling a number out of the black box—isn’t eliminated. But we have brought our guessing process out into the light of day where we can inspect it. And the net result tends to be a more accurate estimate than whatever number happened to pop out of the black box when we first read the question. ([Location 1663](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1663))
- So a forecaster who starts by diving into the inside view risks being swayed by a number that may have little or no meaning. But if she starts with the outside view, her analysis will begin with an anchor that is meaningful. And a better anchor is a distinct advantage. ([Location 1797](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1797))
- Coming up with an outside view, an inside view, and a synthesis of the two isn’t the end. It’s a good beginning. Superforecasters constantly look for other views they can synthesize into their own. ([Location 1836](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1836))
- Forget the old advice to think twice. Superforecasters often think thrice—and sometimes they are just warming up to do a deeper-dive analysis. ([Location 1872](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1872))
- A brilliant puzzle solver may have the raw material for forecasting, but if he doesn’t also have an appetite for questioning basic, emotionally charged beliefs he will often be at a disadvantage relative to a less intelligent person who has a greater capacity for self-critical thinking. It’s not the raw crunching power you have that matters most. It’s what you do with it. ([Location 1883](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1883))
- Active open-mindedness (AOM) is a concept coined by the psychologist Jonathan Baron, who has an office next to mine at the University of Pennsylvania. ([Location 1891](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1891))
- For superforecasters, beliefs are hypotheses to be tested, not treasures to be guarded. It would be facile to reduce superforecasting to a bumper-sticker slogan, but if I had to, that would be it. ([Location 1900](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1900))
## New highlights added April 5, 2022 at 8:27 PM
- While superforecasters do occasionally deploy their own explicit math models, or consult other people’s, that’s rare. The great majority of their forecasts are simply the product of careful thought and nuanced judgment. ([Location 1925](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1925))
- This complex mental dial is the basis of probabilistic thinking. ([Location 2122](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2122))
- Thanks in part to their superior numeracy, superforecasters, like scientists and mathematicians, tend to be probabilistic thinkers. ([Location 2144](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2144))
- An awareness of irreducible uncertainty is the core of probabilistic thinking, but it’s a tricky thing to measure. To do that, we took advantage of a distinction that philosophers have proposed between “epistemic” and “aleatory” uncertainty. Epistemic uncertainty is something you don’t know but is, at least in theory, knowable. If you wanted to predict the workings of a mystery machine, skilled engineers could, in theory, pry it open and figure it out. Mastering mechanisms is a prototypical clocklike forecasting challenge. Aleatory uncertainty is something you not only don’t know; it is unknowable. No matter how much you want to know whether it will rain in Philadelphia one year from now, no matter how many great meteorologists you consult, you can’t outguess the seasonal averages. You are dealing with an intractably cloud-like problem, with uncertainty that it is impossible, even in theory, to eliminate. Aleatory uncertainty ensures life will always have surprises, regardless of how carefully we plan. ([Location 2145](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2145))
- Barbara Mellers has shown that granularity predicts accuracy: the average forecaster who sticks with the tens—20%, 30%, 40%—is less accurate than the finer-grained forecaster who uses fives—20%, 25%, 30%—and still less accurate than the even finer-grained forecaster who uses ones—20%, 21%, 22%. ([Location 2177](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2177))
- In Kahneman’s terms, probabilistic thinkers take the outside view toward even profoundly identity-defining events, seeing them as quasi-random draws from distributions of once-possible worlds. ([Location 2265](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2265))
- So finding meaning in events is positively correlated with well-being but negatively correlated with foresight. That sets up a depressing possibility: Is misery the price of accuracy? ([Location 2284](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2284))
## New highlights added April 7, 2022 at 6:55 PM
- Unpack the question into components. Distinguish as sharply as you can between the known and unknown and leave no assumptions unscrutinized. Adopt the outside view and put the problem into a comparative perspective that downplays its uniqueness and treats it as a special case of a wider class of phenomena. Then adopt the inside view that plays up the uniqueness of the problem. Also explore the similarities and differences between your views and those of others—and pay special attention to prediction markets and other methods of extracting wisdom from crowds. Synthesize all these different views into a single vision as acute as that of a dragonfly. Finally, express your judgment as precisely as you can, using a finely grained scale of probability. ([Location 2290](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2290))
- Forecasts aren’t like lottery tickets that you buy and file away until the big draw. They are judgments that are based on available information and that should be updated in light of changing information. ([Location 2297](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2297))
- Superforecasters do monitor the news carefully and factor it into their forecasts, which is bound to give them a big advantage over the less attentive. If that’s the decisive factor, then superforecasters’ success would tell us nothing more than “it helps to pay attention and keep your forecast up to date”—which is about as enlightening as being told that when polls show a candidate surging into a comfortable lead he is more likely to win. ([Location 2323](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2323))
- Good updating requires the same skills used in making the initial forecast and is often just as demanding. It can even be more challenging. ([Location 2329](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2329))
- So there are two dangers a forecaster faces after making the initial call. One is not giving enough weight to new information. That’s underreaction. The other danger is overreacting to new information, seeing it as more meaningful than it is, and adjusting a forecast too radically. Both under- and overreaction can diminish accuracy. Both can also, in extreme cases, destroy a perfectly good forecast. ([Location 2373](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2373))
- This is an extreme case of what psychologists call “belief perseverance.” People can be astonishingly intransigent—and capable of rationalizing like crazy to avoid acknowledging new information that upsets their settled beliefs. ([Location 2404](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2404))
- Fortunately, such extreme obstinacy is rare. More commonly, when we are confronted by facts impossible to ignore, we budge, grudgingly, but the degree of change is likely to be less than it should be. ([Location 2409](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2409))
- And I have now confessed to the world. Was that hard? Not really. Many smart people made the same mistake, so it’s not embarrassing to own up to it. The quotation wasn’t central to my work and being right about it wasn’t part of my identity. ([Location 2417](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2417))
- Social psychologists have long known that getting people to publicly commit to a belief is a great way to freeze it in place, making it resistant to change. The stronger the commitment, the greater the resistance. ([Location 2419](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2419))
- Our beliefs about ourselves and the world are built on each other in a Jenga-like fashion. ([Location 2429](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2429))
- Psycho-logic trumps logic. ([Location 2436](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2436))
- This suggests that superforecasters may have a surprising advantage: they’re not experts or professionals, so they have little ego invested in each forecast. Except in rare circumstances—when Jean-Pierre Beugoms answers military questions, for example—they aren’t deeply committed to their judgments, which makes it easier to admit when a forecast is offtrack and adjust. This isn’t to say that superforecasters have zero ego investment. They care about their reputations among their teammates. And if “superforecaster” becomes part of their self-concept, their commitment will grow fast. But still, the self-esteem stakes are far less than those for career CIA analysts or acclaimed pundits with their reputations on the line. And that helps them avoid underreaction when new evidence calls for updating beliefs. ([Location 2443](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2443))
- Psychologists call this the dilution effect, and given that stereotypes are themselves a source of bias we might say that diluting them is all to the good. Yes and no. Yes, it is possible to fight fire with fire, and bias with bias, but the dilution effect remains a bias. Remember what’s going on here. People base their estimate on what they think is a useful tidbit of information. Then they encounter clearly irrelevant information—meaningless noise—which they indisputably should ignore. But they don’t. They sway in the wind, at the mercy of the next random gust of irrelevant information. Such swaying is overreaction, a common and costly mistake. ([Location 2465](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2465))
- As with underreaction, the key is commitment—in this case, the absence of commitment. Traders who constantly buy and sell are not cognitively or emotionally connected to their stocks. They expect some to fall and they sell off these losers with a shrug. Malkiel’s metaphor is apt. They are no more committed to these stocks than a gin rummy player is to cards in his hand, leaving them free to overreact to information “obviously of an ephemeral and nonsignificant character.” ([Location 2482](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2482))
- Forecasters should feel the same about under- and overreaction to new information, the Scylla and Charybdis of forecasting. Good updating is all about finding the middle passage. ([Location 2490](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2490))
- It’s not dramatic. It’s even, to be candid, a tad boring. Tim will never become a guru who shares his visionary insights in TV appearances, bestselling books, and corporate gigs. But Tim’s way works. The tournament data prove it: superforecasters not only update more often than other forecasters, they update in smaller increments. ([Location 2526](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2526))
- A forecaster who doesn’t adjust her views in light of new information won’t capture the value of that information, while a forecaster who is so impressed by the new information that he bases his forecast entirely on it will lose the value of the old information that underpinned his prior forecast. But the forecaster who carefully balances old and new captures the value in both—and puts it into her new forecast. The best way to do that is by updating often but bit by bit. ([Location 2529](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2529))
- The superforecasters are a numerate bunch: many know about Bayes’ theorem and could deploy it if they felt it was worth the trouble. But they rarely crunch the numbers so explicitly. What matters far more to the superforecasters than Bayes’ theorem is Bayes’ core insight of gradually getting closer to the truth by constantly updating in proportion to the weight of the evidence. ([Location 2569](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2569))
- Minto is a Bayesian who does not use Bayes’ theorem. That paradoxical description applies to most superforecasters. ([Location 2575](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2575))
- In his famous essay “Politics and the English Language,” George Orwell concluded with six emphatic rules, including “never use a long word where a short one will do” and “never use the passive where you can use the active.” But the sixth rule was the key: “Break any of these rules sooner than saying anything outright barbarous.” ([Location 2586](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2586))
- Superforecasters understand the principles but also know that their application requires nuanced judgments. And they would rather break the rules than make a barbarous forecast. ([Location 2591](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2591))
## New highlights added April 8, 2022 at 10:55 AM
- The psychologist Carol Dweck would say Simpson has a “growth mindset,” which Dweck defines as believing that your abilities are largely the product of effort—that you can “grow” to the extent that you are willing to work hard and learn.2 Some people might think that’s so obviously true it scarcely needs to be said. But as Dweck’s research has shown, the growth mindset is far from universal. Many people have what she calls a “fixed mindset”—the belief that we are who we are, and abilities can only be revealed, not created and developed. People with the fixed mindset say things like “I’m bad at math” and see that as an immutable feature of who they are, like being left-handed or female or tall. This has serious consequences. ([Location 2604](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2604))
- To be a top-flight forecaster, a growth mindset is essential. ([Location 2626](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2626))
- For Keynes, failure was an opportunity to learn—to identify mistakes, spot new alternatives, and try again. ([Location 2648](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2648))
- Keynes operated on a higher plane than most of us, but that process—try, fail, analyze, adjust, try again—is fundamental to how all of us learn, almost from the moment we are born. ([Location 2658](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2658))
- We learn new skills by doing. We improve those skills by doing more. These fundamental facts are true of even the most demanding skills. ([Location 2668](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2668))
- Fortune favors the prepared mind. ([Location 2691](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2691))
- Effective practice also needs to be accompanied by clear and timely feedback. My research collaborator Don Moore points out that police officers spend a lot of time figuring out who is telling the truth and who is lying, but research has found they aren’t nearly as good at it as they think they are and they tend not to get better with experience. That’s because experience isn’t enough. It must be accompanied by clear feedback. ([Location 2694](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2694))
- Research on calibration—how closely your confidence matches your accuracy—routinely finds people are too confident.10 But overconfidence is not an immutable law of human nature. ([Location 2704](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2704))
- To learn from failure, we must know when we fail. ([Location 2709](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2709))
- When a forecaster says something could or might or may happen, she could or might or may be saying almost anything. ([Location 2714](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2714))
- Vague language is elastic language. ([Location 2722](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2722))
- The second big barrier to feedback is time lag. When forecasts span months or years, the wait for a result allows the flaws of memory to creep in. ([Location 2724](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2724))
- Not only will you have to contend with ordinary forgetfulness, you are likely to be afflicted by what psychologists call hindsight bias. ([Location 2726](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2726))
- Once we know the outcome of something, that knowledge skews our perception of what we thought before we knew the outcome: that’s hindsight bias. ([Location 2744](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2744))
- Forecasters who use ambiguous language and rely on flawed memories to retrieve old forecasts don’t get clear feedback, which makes it impossible to learn from experience. ([Location 2754](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2754))
- By the way, there are no shortcuts. Bridge players may develop well-calibrated judgment when it comes to bidding on tricks, but research shows that judgment calibrated in one context transfers poorly, if at all, to another. So if you were thinking of becoming a better political or business forecaster by playing bridge, forget it. To get better at a certain type of forecasting, that is the type of forecasting you must do—over and over again, with good feedback telling you how your training is going, and a cheerful willingness to say, “Wow, I got that one wrong. I’d better think about why.” ([Location 2766](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2766))
- Sometimes they share lengthy postmortems with teammates. These online discussions can go on for pages. And there’s a lot more introspection when superforecasters have quiet moments to themselves. ([Location 2778](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2778))
- People often assume that when a decision is followed by a good outcome, the decision was good, which isn’t always true, and can be dangerous if it blinds us to the flaws in our thinking. ([Location 2788](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2788))
- Even with a growth mindset, the forecaster who wants to improve has to have a lot of what my colleague Angela Duckworth dubbed “grit.” ([Location 2805](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2805))
- Grit is passionate perseverance of long-term goals, even in the face of frustration and failure. Married with a growth mindset, it is a potent force for personal progress. ([Location 2810](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2810))
- Anne’s tenacity is daunting. When the tournament asked a question about refugee numbers in the Central Africa Republic, she went to the UN’s website and saw the data were a week old. Rather than assume those were the most recent numbers available, she e-mailed the agency and asked how often the data were updated and when the next update could be expected. She also noticed their data showed large fluctuations. Again, she queried the agency. ([Location 2833](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2833))
- There is always more trying, more failing, more analyzing, more adjusting, and trying again. Computer programmers have a wonderful term for a program that is not intended to be released in a final version but will instead be used, analyzed, and improved without end. It is “perpetual beta.” Superforecasters are perpetual beta. ([Location 2848](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2848))
- The strongest predictor of rising into the ranks of superforecasters is perpetual beta, the degree to which one is committed to belief updating and self-improvement. ([Location 2873](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2873))
- In his 1972 classic, Victims of Groupthink, the psychologist Irving Janis—one of my PhD advisers at Yale long ago—explored the decision making that went into both the Bay of Pigs invasion and the Cuban missile crisis. ([Location 2926](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2926))
- How the Kennedy White House changed its decision-making culture for the better is a must-read for students of management and public policy because it captures the dual-edged nature of working in groups. Teams can cause terrible mistakes. They can also sharpen judgment and accomplish together what cannot be done alone. ([Location 2950](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2950))
- Groups can be wise, or mad, or both. What makes the difference isn’t just who is in the group, Kennedy’s circle of advisers demonstrated. The group is its own animal. ([Location 2955](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2955))
- We also gave teams a primer on teamwork based on insights gleaned from research in group dynamics. On the one hand, we warned, groupthink is a danger. Be cooperative but not deferential. Consensus is not always good; disagreement not always bad. If you do happen to agree, don’t take that agreement—in itself—as proof that you are right. Never stop doubting. Pointed questions are as essential to a team as vitamins are to a human body. ([Location 2981](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2981))
- Since Socrates, good teachers have practiced precision questioning, but still it’s often not used when it’s needed most. ([Location 2994](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=2994))
- Tell someone they’re exceptionally good at something and they may start taking their superiority for granted. Surround them with others who are similarly accomplished, tell them how special they are, and egos may swell even more. Rather than spur a superforecaster to take his game to the next level, it might make him so sure of himself that he is tempted to think his judgment must be right because it is his judgment. This is a familiar paradox: success can lead to acclaim that can undermine the habits of mind that produced the success. Such hubris often afflicts highly accomplished individuals. In business circles, it is called CEO disease. ([Location 3010](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3010))
- Seeing this “dancing around,” people realized that excessive politeness was hindering the critical examination of views, so they made special efforts to assure others that criticism was welcome. ([Location 3029](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3029))
- When Marty felt people weren’t explaining their forecasts enough to get good discussions going, he explained his in greater detail and invited comments. He also organized a conference call to hash out workloads, with details handled by him—and most of the team signed up. ([Location 3041](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3041))
- Most teams have a nucleus of five or six members who do most of the work. Within that core, we might expect to see a division of labor that reduces the amount of effort any one person needs to invest in the task, at least if he or she approached forecasting as work, not play. But we saw the opposite on the best teams: workloads were divided, but as commitment grew, so did the amount of effort forecasters put into it. ([Location 3054](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3054))
- So just as we surveyed individuals to test their active open-mindedness (AOM), we surveyed teams to probe their attitudes toward the group and patterns of interaction within the group—that is, we tested the team’s AOM. ([Location 3108](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3108))
- But what makes a team more or less actively open-minded? You might think it’s the individuals on the team. Put high-AOM people in a team and you’ll get a high-AOM team; put lower-AOM people in a team and you’ll get a lower-AOM team. Not so, as it turns out. Teams were not merely the sum of their parts. How the group thinks collectively is an emergent property of the group itself, a property of communication patterns among group members, not just the thought processes inside each member.8 A group of open-minded people who don’t care about one another will be less than the sum of its open-minded parts. A group of opinionated people who engage one another in pursuit of the truth will be more than the sum of its opinionated parts. ([Location 3110](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3110))
- My Wharton colleague Adam Grant categorizes people as “givers,” “matchers,” and “takers.” Givers are those who contribute more to others than they receive in return; matchers give as much as they get; takers give less than they take. ([Location 3117](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3117))
- As we have seen, the aggregation of different perspectives is a potent way to improve judgment, but the key word is different. Combining uniform perspectives only produces more of the same, while slight variation will produce slight improvement. It is the diversity of the perspectives that makes the magic work. Superteams were fairly diverse—because superforecasters are fairly diverse—but we didn’t design them with that in mind. We put ability first. If Page is right, we might have gotten even better results if we had made diversity the key determinant of team membership and let ability take care of itself. ([Location 3138](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3138))
- Indeed, extremizing gave regular forecaster teams a big enough boost to pass some superteams, and extremizing a large pool of regular forecasters produced, as we saw earlier, tournament-winning results. ([Location 3156](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3156))
- LEADERS MUST DECIDE, and to do that they must make and use forecasts. The more accurate those forecasts are, the better, so the lessons of superforecasting should be of intense interest to them. But leaders must also act and achieve their goals. In a word, they must lead. ([Location 3163](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3163))
- Ask people to list the qualities an effective leader must have, or consult the cottage industry devoted to leadership coaching, or examine rigorous research on the subject, and you will find near-universal agreement on three basic points. Confidence will be on everyone’s list. Leaders must be reasonably confident, and instill confidence in those they lead, because nothing can be accomplished without the belief that it can be. Decisiveness is another essential attribute. Leaders can’t ruminate endlessly. They need to size up the situation, make a decision, and move on. And leaders must deliver a vision—the goal that everyone strives together to achieve. ([Location 3166](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3166))
- Leaders must be forecasters and leaders but it seems that what is required to succeed at one role may undermine the other. ([Location 3180](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3180))
## New highlights added April 8, 2022 at 4:24 PM
- “In war, everything is uncertain,” wrote Helmuth von Moltke.1 In the late nineteenth century, Moltke was famous the world over after he led Prussian forces to victory against Denmark in 1864, Austria in 1866, and France in 1871—victories that culminated in the unification of Germany. His writings on war—which were themselves influenced by the great theorist Carl von Clausewitz—profoundly shaped the German military that fought the two world wars. But Moltke was no Napoleon. He never saw himself as a visionary leader directing his army like chess pieces. ([Location 3186](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3186))
- The fundamental message: think. If necessary, discuss your orders. Even criticize them. And if you absolutely must—and you better have a good reason—disobey them.4 ([Location 3215](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3215))
- The time devoted to a decision was constrained by circumstances, so decision making could be leisurely and complex or—when bullets were flying—abrupt and simple. If this meant a decision wasn’t as informed as it could be, that was fine. An imperfect decision made in time was better than a perfect one made too late. ([Location 3219](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3219))
- So a leader must possess unwavering determination to overcome obstacles and accomplish his goals—while remaining open to the possibility that he may have to throw out the plan and try something else. ([Location 3231](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3231))
- Auftragstaktik blended strategic coherence and decentralized decision making with a simple principle: commanders were to tell subordinates what their goal is but not how to achieve it. ([Location 3243](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3243))
- Petraeus’s insistence on intellectual flexibility—“the most powerful tool any soldier carries is not his weapon but his mind,” he says—is still controversial in the army. ([Location 3362](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3362))
- Armies are unusual organizations, but bosses everywhere feel the tension between control and innovation, which is why Moltke’s spirit can be found in organizations that have nothing to do with bullets and bombs. ([Location 3377](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3377))
- “You have to have tremendous humility in the face of the game because the game is extremely complex, you won’t solve it, it’s not like tic-tac-toe or checkers,” she says. “It’s very hard to master and if you’re not learning all the time, you will fail. That being said, humility in the face of the game is extremely different than humility in the face of your opponents.” Duke feels confident that she can compete with most people she sits down with at a poker table. “But that doesn’t mean I think I’ve mastered this game.” ([Location 3420](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3420))
- The humility required for good judgment is not self-doubt—the sense that you are untalented, unintelligent, or unworthy. It is intellectual humility. It is a recognition that reality is profoundly complex, that seeing things clearly is a constant struggle, when it can be done at all, and that human judgment must therefore be riddled with mistakes. This is true for fools and geniuses alike. So it’s quite possible to think highly of yourself and be intellectually humble. ([Location 3425](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3425))
- Intellectual humility compels the careful reflection necessary for good judgment; confidence in one’s abilities inspires determined action. ([Location 3429](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3429))
- Forecasters who can’t cope with the dissonance risk making the most serious possible forecasting error in a conflict: underestimating your opponent. ([Location 3437](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3437))
- There is no divinely mandated link between morality and competence. ([Location 3438](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3438))
- Forecasters who see illusory correlations and assume that moral and cognitive weakness run together will fail when we need them most. ([Location 3440](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3440))
- Coping with dissonance is hard. “The test of a first-rate intelligence is the ability to hold two opposed ideas in mind at the same time and still retain the ability to function,” F. Scott Fitzgerald observed in “The Crack-Up.” ([Location 3442](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3442))
- There is no logical contradiction, just a psycho-logical tension. If you want to become a superforecaster, you must overcome it. ([Location 3445](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3445))
- Kahneman is the accidental Nobelist, the cognitive psychologist who had no training in economics but whose work shook the foundations of the field. ([Location 3457](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3457))
- Talking to Kahneman can be a Socratic experience: energizing as long as you don’t hunker down into a defensive crouch. So in the summer of 2014, when it was clear that superforecasters were not merely superlucky, Kahneman cut to the chase: “Do you see them as different kinds of people, or as people who do different kinds of things?” My answer was, “A bit of both.” They score higher than average on measures of intelligence and open-mindedness, although they are not off the charts. What makes them so good is less what they are than what they do—the hard work of research, the careful thought and self-criticism, the gathering and synthesizing of other perspectives, the granular judgments and relentless updating. ([Location 3459](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3459))
- As we saw, people can, in principle, use conscious System 2 reflection to catch mistakes arising from a rapid, unconscious System 1 operations. Superforecasters put enormous effort into doing just that. But the continuous self-scrutiny is exhausting, and the feeling of knowing is seductive. Surely even the best of us will inevitably slip back into easier, intuitive modes of thinking. ([Location 3465](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3465))
- My sense is that some superforecasters are so well practiced in System 2 corrections—such as stepping back to take the outside view—that these techniques have become habitual. In effect, they are now part of their System 1. That may sound bizarre but it’s not an unusual process. ([Location 3540](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3540))
- So how long can superforecasters defy the laws of psychological gravity? The answer to that depends on how heavy their cognitive loads are. Turning a self-conscious System 2 correction into an unconscious System 1 operation may lighten the load considerably. So may the software tools some superforecasters have developed—like Doug Lorch’s new-source selection program designed to correct the System 1 bias in favor of the like-minded. But still, superforecasting remains hard work. Those who do it well appreciate the fragility of their success. They expect to stumble. And when they do, they will get up, try to draw the right lessons, and keep forecasting. ([Location 3549](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3549))
- What matters can’t be forecast and what can be forecast doesn’t matter. Believing otherwise lulls us into a false sense of security. In this view, I have taken a scientific step backward. ([Location 3565](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3565))
- I see Kahneman’s and Taleb’s critiques as the strongest challenges to the notion of superforecasting. We are far enough apart empirically and close enough philosophically to make communication, even collaboration, possible. ([Location 3625](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3625))
- If you have to plan for a future beyond the forecasting horizon, plan for surprise. ([Location 3661](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3661))
- Taleb has taken this argument further and called for critical systems—like international banking and nuclear weapons—to be made “antifragile,” meaning they are not only resilient to shocks but strengthened by them. ([Location 3665](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3665))
- We have to set priorities, which puts us back in the forecasting business. ([Location 3668](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3668))
- Probability judgments should be explicit so we can consider whether they are as accurate as they can be. And if they are nothing but a guess, because that’s the best we can do, we should say so. Knowing what we don’t know is better than thinking we know what we don’t. ([Location 3678](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3678))
- Kahneman and other pioneers of modern psychology have revealed that our minds crave certainty and when they don’t find it, they impose it. In forecasting, hindsight bias is the cardinal sin. ([Location 3682](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3682))
- Now comes the hardest-to-grasp part of Taleb’s view of the world. He posits that historical probabilities—all the possible ways the future could unfold—are distributed like wealth, not height. That means our world is vastly more volatile than most of us realize and we are at risk of grave miscalculations. ([Location 3701](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3701))
- The past did not have to unfold as it did, the present did not have to be what it is, and the future is wide open. History is a virtually infinite array of possibilities. ([Location 3722](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3722))
- Counterfactuals highlight how radically open the possibilities once were and how easily our best-laid plans can be blown away by flapping butterfly wings. Immersion in what-if history can give us a visceral feeling for Taleb’s vision of radical indeterminacy. Savoring how history could have generated an infinite array of alternative outcomes and could now generate a similar array of alternative futures, is like contemplating the one hundred billion known stars in our galaxy and the one hundred billion known galaxies. It instills profound humility.16 ([Location 3733](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3733))
- Tournaments help researchers learn what improves forecasting and help forecasters sharpen their skills with practice and feedback. Tournaments could help society, too, by providing tools for structuring our thinking about what is likely to happen if we venture down one policy path or another. ([Location 3776](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3776))
- Forecast, measure, revise: it is the surest path to seeing better. ([Location 3780](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3780))
- Just as we now expect a pill to have been tested in peer-reviewed experiments before we swallow it, we will expect forecasters to establish the accuracy of their forecasting with rigorous testing before we heed their advice. ([Location 3783](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3783))
- Arguments and evidence are lovely adornments but what matters is the ceaseless contest to be the kto, not the kogo. 6 It follows that the goal of forecasting is not to see what’s coming. It is to advance the interests of the forecaster and the forecaster’s tribe. Accurate forecasts may help do that sometimes, and when they do accuracy is welcome, but it is pushed aside if that’s what the pursuit of power requires. ([Location 3809](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3809))
- If kto-kogo were the decisive force in human affairs that Lenin and others took it to be, evidence-based medicine—which was a threat to everyone who was anyone in the medical hierarchy—would have been stillborn. But Ernest Codman, Archie Cochrane, and many others overcame entrenched interests. They did it not by storming the ramparts. They did it with reason and a relentless focus on the singular goal of making the sick well. ([Location 3845](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3845))
- Evidence-based policy is a movement modeled on evidence-based medicine, with the goal of subjecting government policies to rigorous analysis so that legislators will actually know—not merely think they know—whether policies do what they are supposed to do. ([Location 3848](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3848))
- We can count and test like never before. And we are. Seen in this broader perspective, an evidence-based forecasting movement would not be a startling change springing up out of nothing. It would be another manifestation of a broad and deep shift away from decision making based on experience, intuition, and authority—“Do this because I think it will work and I’m an expert”—toward quantification and analysis. Far from being surprising, one might even think, “What took so long?” ([Location 3865](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3865))
- Recall the wrong-side-of-maybe fallacy that leads people to conclude a forecast of “There is a 70% chance an event will happen” is wrong if the event doesn’t happen. It was a big reason why Sherman Kent’s modest proposal to attach numerical ranges to forecasts went nowhere. Use the number and you risk being unfairly blamed. Stick with phrases as fuzzy as a puff of smoke and you are safe. ([Location 3872](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3872))
- What would help is a sweeping commitment to evaluation: Keep score. Analyze results. Learn what works and what doesn’t. But that requires numbers, and numbers would leave the intelligence community vulnerable to the wrong-side-of-maybe fallacy, lacking any cover the next time they blow a big call. ([Location 3882](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3882))
- Balancing it all out, count me as cautiously optimistic that my work may contribute to an evidence-based forecasting movement. But this is not a prospect everyone embraces. I need only imagine how my life might have gone differently to know how the objection might be framed. ([Location 3892](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3892))
- Numbers are fine and useful things, I would say in that alternate universe, but we must be careful not to be smitten with them. “Not everything that counts can be counted,” goes a famous saying, “and not everything that can be counted counts.”13 In this era of computers and algorithms, some social scientists have forgotten that. ([Location 3899](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3899))
- This naive positivism is running rampant, taking over domains it has no business being in. As Wieseltier poetically put it, “Where wisdom once was, quantification will now be.” ([Location 3904](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3904))
- Far too many people treat numbers like sacred totems offering divine insight. The truly numerate know that numbers are tools, nothing more, and their quality can range from wretched to superb. ([Location 3906](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3906))
- Numbers must be constantly scrutinized and improved, which can be an unnerving process because it is unending. Progressive improvement is attainable. Perfection is not.15 ([Location 3909](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3909))
- One problem is that Brier scores treat false alarms the same as misses. But when it comes to things like terrorist attacks, people are far more concerned about misses than false alarms. Fortunately, adjusting the scoring to capture this concern is easy. Forecasters just have to be told in advance what the ground rules are—“False positives will cost you one-tenth as much as false negatives”—so they can adjust their judgments accordingly. ([Location 3912](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3912))
- The challenge runs deeper, and it brings us back to that line about the countable not always being worth counting. ([Location 3922](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3922))
- What matters is the big question, but the big question can’t be scored. The little question doesn’t matter but it can be scored, so the IARPA tournament went with it. You could say we were so hell-bent on looking scientific that we counted what doesn’t count. ([Location 3931](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3931))
- That one tiny question doesn’t nail down the big question, but it does contribute a little insight. And if we ask many tiny-but-pertinent questions, we can close in on an answer for the big question. ([Location 3942](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3942))
- Another way to think of it is to imagine a painter using the technique called pointillism. It consists of dabbing tiny dots on the canvas, nothing more. Each dot alone adds little. But as the dots collect, patterns emerge. With enough dots, an artist can produce anything from a vivid portrait to a sweeping landscape. ([Location 3949](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3949))
- For one thing, I called my research program the Good Judgment Project, which seems to imply that accurate forecasting and good judgment are one and the same. But that’s not what I intended. Foresight is one element of good judgment, but there are others, including some that cannot be counted and run through a scientist’s algorithms—moral judgment, for one. Another critical dimension of good judgment is asking good questions. Indeed, a farsighted forecast flagging disaster or opportunity can’t happen until someone thinks to pose the question. What qualifies as a good question? It’s one that gets us thinking about something worth thinking about. So one way to identify a good question is what I call the smack-the-forehead test: when you read the question after time has passed, you smack your forehead and say, “If only I had thought of that before!” ([Location 3954](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3954))
- While we may assume that a superforecaster would also be a superquestioner, and vice versa, we don’t actually know that. Indeed, my best scientific guess is that they often are not. ([Location 3969](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3969))
- As a forecast, that’s not terribly helpful. This sort of thing is why some people see Friedman as a particularly successful and slippery pundit who has mastered the art of appearing to go out on a limb without ever venturing out. But the same column can be read less as a forecast than an attempt to draw the attention of forecasters to something they should be thinking about. In other words, it is a question, not an answer. ([Location 3980](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3980))
- That’s a tall order. But there’s a much bigger collaboration I’d like to see. It would be the Holy Grail of my research program: using forecasting tournaments to depolarize unnecessarily polarized policy debates and make us collectively smarter. ([Location 3988](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=3988))
- These are accomplished people debating pressing issues, but nobody seems to have learned anything beyond how to defend their original position. ([Location 4021](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=4021))
- When a debate like “Keynesians versus Austerians” emerges, key figures could work together—with the help of trusted third parties—to identify what they disagree about and which forecasts would meaningfully test those disagreements. The key is precision. It’s one thing for Austerians to say a policy will cause inflation and Keynesians to say it won’t. But how much inflation? Measured by what benchmark? Over what time period? The result must be a forecast question that reduces ambiguity to an absolute minimum. ([Location 4025](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=4025))
- A major point of view rarely has zero merit, and if a forecasting contest produces a split decision we will have learned that the reality is more mixed than either side thought. If learning, not gloating, is the goal, that is progress. ([Location 4032](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=4032))
- Each side wanted to be right but they wanted the truth more. ([Location 4035](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=4035))
- We hear them most because they are the loudest and the media reward people who shout into bullhorns. But there are less voluble and more reasonable voices. With their adversaries and a moderator, let them design clear tests of their beliefs. ([Location 4037](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=4037))
