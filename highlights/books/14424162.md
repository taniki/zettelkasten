# Superforecasting

![rw-book-cover](https://images-na.ssl-images-amazon.com/images/I/51%2BcBe-c2UL._SL200_.jpg)

## Metadata
- Author: [[Philip Tetlock and Dan Gardner]]
- Full Title: Superforecasting
- Category: books

## Highlights
- He was aiming for a PhD in math, but he realized it was beyond his abilities—“I had my nose rubbed in my limitations” is how he puts it—and he dropped out. It wasn’t wasted time, however. Classes in ornithology made Bill an avid bird-watcher, and because Arizona is a great place to see birds, he did fieldwork part-time for scientists, then got a job with the Department of Agriculture and stayed for a while. ([Location 53](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=53))
- What my research had shown was that the average expert had done little better than guessing on many of the political and economic questions I had posed. “Many” does not equal all. It was easiest to beat chance on the shortest-range questions that only required looking one year out, and accuracy fell off the further out experts tried to forecast—approaching the dart-throwing-chimpanzee level three to five years out. That was an important finding. ([Location 109](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=109))
- I believe it is possible to see into the future, at least in some situations and to some extent, and that any intelligent, open-minded, and hardworking person can cultivate the requisite skills. ([Location 122](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=122))
## New highlights added March 30, 2022 at 5:36 AM
- In one of history’s great ironies, scientists today know vastly more than their colleagues a century ago, and possess vastly more data-crunching power, but they are much less confident in the prospects for perfect predictability. ([Location 177](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=177))
- How predictable something is depends on what we are trying to predict, how far into the future, and under what circumstances. ([Location 223](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=223))
- Laws of physics aside, there are no universal constants, so separating the predictable from the unpredictable is difficult work. There’s no way around it. ([Location 232](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=232))
- Big leaps in computing power and continued refinement of forecasting models may nudge the limits a little further into the future but those advances gradually get harder and the payoffs shrink toward zero. How good can it get? No one knows. But knowing the current limits is itself a success. ([Location 239](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=239))
- That’s because the forecast-measure-revise procedure operates only within the rarefied confines of high-tech forecasting, such as the work of macroeconomists at central banks or marketing and financial professionals in big companies or opinion poll analysts like Nate Silver.7 More often forecasts are made and then … nothing. Accuracy is seldom determined after the fact and is almost never done with sufficient regularity and rigor that conclusions can be drawn. The reason? Mostly it’s a demand-side problem: The consumers of forecasting—governments, business, and the public—don’t demand evidence of accuracy. So there is no measurement. Which means no revision. And without revision, there can be no improvement. ([Location 243](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=243))
- “I have been struck by how important measurement is to improving the human condition,” Bill Gates wrote. “You can achieve incredible progress if you set a clear goal and find a measure that will drive progress toward that goal. … This may seem basic, but it is amazing how often it is not done and how hard it is to get right.” ([Location 252](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=252))
- Sometimes forecasts are used to advance political agendas and galvanize action—as activists hope to do when they warn of looming horrors unless we change our ways. ([Location 260](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=260))
- This jumble of goals is seldom acknowledged, which makes it difficult to even start working toward measurement and progress. It’s a messy situation, which doesn’t seem to be getting better. ([Location 264](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=264))
- For scientists, not knowing is exciting. It’s an opportunity to discover; the more that is unknown, the greater the opportunity. ([Location 268](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=268))
- In year 1, GJP beat the official control group by 60%. In year 2, we beat the control group by 78%. GJP also beat its university-affiliated competitors, including the University of Michigan and MIT, by hefty margins, from 30% to 70%, and even outperformed professional intelligence analysts with access to classified data. After two years, GJP was doing so much better than its academic competitors that IARPA dropped the other teams.10 ([Location 296](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=296))
- Foresight isn’t a mysterious gift bestowed at birth. It is the product of particular ways of thinking, of gathering information, of updating beliefs. These habits of thought can be learned and cultivated by any intelligent, thoughtful, determined person. ([Location 303](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=303))
- For centuries, it hobbled progress in medicine. When physicians finally accepted that their experience and perceptions were not reliable means of determining whether a treatment works, they turned to scientific testing—and medicine finally started to make rapid advances. The same revolution needs to happen in forecasting. ([Location 317](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=317))
- As with the experts who had real foresight in my earlier research, what matters most is how the forecaster thinks. I’ll describe this in detail, but broadly speaking, superforecasting demands thinking that is open-minded, careful, curious, and—above all—self-critical. It also demands focus. The kind of thinking that produces superior judgment does not come effortlessly. Only the determined can deliver it reasonably consistently, which is why our analyses have consistently found commitment to self-improvement to be the strongest predictor of performance. ([Location 334](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=334))
- Human thought is beset by psychological pitfalls, a fact that has only become widely recognized in the last decade or two. ([Location 382](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=382))
## New highlights added March 31, 2022 at 11:41 AM
- If patients who were identical in every way were put into two groups, and the groups were treated differently, he wrote, we would know the treatment caused any difference in outcome. It seems simple but is impossible in practice because no two people are exactly alike, not even identical twins, so the experiment will be confounded by the differences among test subjects. The solution lay in statistics: Randomly assigning people to one group or the other would mean whatever differences there are among them should balance out if enough people participated in the experiment. Then we can confidently conclude that the treatment caused any differences in observed outcomes. It isn’t perfect. There is no perfection in our messy world. But it beats wise men stroking their chins. ([Location 465](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=465))
## New highlights added March 31, 2022 at 11:01 PM
- Like everyone else, scientists have intuitions. Indeed, hunches and flashes of insight—the sense that something is true even if you can’t prove it—have been behind countless breakthroughs. The interplay between System 1 and System 2 can be subtle and creative. But scientists are trained to be cautious. They know that no matter how tempting it is to anoint a pet hypothesis as The Truth, alternative explanations must get a hearing. And they must seriously consider the possibility that their initial hunch is wrong. ([Location 609](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=609))
- The key is doubt. Scientists can feel just as strongly as anyone else that they know The Truth. But they know they must set that feeling aside and replace it with finely measured degrees of doubt—doubt that can be reduced (although never to zero) by better evidence from better studies. ([Location 615](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=615))
- Formally, it’s called attribute substitution, but I call it bait and switch: when faced with a hard question, we often surreptitiously replace it with an easy one. ([Location 634](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=634))
- There is nothing mystical about an accurate intuition like the fire commander’s. It’s pattern recognition. With training or experience, people can encode patterns deep in their memories in vast number and intricate detail—such as the estimated fifty thousand to one hundred thousand chess positions that top players have in their repertoire.20 If something doesn’t fit a pattern—like a kitchen fire giving off more heat than a kitchen fire should—a competent expert senses it immediately. ([Location 676](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=676))
## New highlights added April 1, 2022 at 1:03 AM
- Learning the cues is a matter of opportunity and effort. Sometimes learning the cues is easy. “A child does not need thousands of examples to learn to discriminate dogs from cats.” But other patterns are much harder to master, like the estimated ten thousand hours of practice it takes to learn those fifty thousand to one hundred thousand chess patterns. ([Location 689](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=689))
- The tip-of-your-nose perspective can work wonders but it can also go terribly awry, so if you have the time to think before making a big decision, do so—and be prepared to accept that what seems obviously true now may turn out to be false later. ([Location 700](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=700))
- All too often, forecasting in the twenty-first century looks too much like nineteenth-century medicine. There are theories, assertions, and arguments. There are famous figures, as confident as they are well compensated. But there is little experimentation, or anything that could be called science, so we know much less than most people realize. And we pay the price. Although bad forecasting rarely leads as obviously to harm as does bad medicine, it steers us subtly toward bad decisions and all that flows from them—including monetary losses, missed opportunities, unnecessary suffering, even war and death. Happily, physicians now know the cure for all this. It is a tablespoon of doubt. ([Location 713](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=713))
- Bringing the rigor of measurement to forecasting might seem easier to do: collect forecasts, judge their accuracy, add the numbers. That’s it. ([Location 721](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=721))
- The first step in learning what works in forecasting, and what doesn’t, is to judge forecasts, and to do that we can’t make assumptions about what the forecast means. We have to know. There can’t be any ambiguity about whether a forecast is accurate or not and Ballmer’s forecast is ambiguous. ([Location 734](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=734))
- So here are two forecasts of the sort we routinely encounter. They are serious attempts by smart people to grapple with big issues. Their meaning seems clear. When time passes, their accuracy seems obvious. But it’s not. For various reasons, it’s impossible to say these forecasts are right or wrong beyond all dispute. The truth is, the truth is elusive. ([Location 769](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=769))
- In intelligence circles, Sherman Kent is a legend. With a PhD in history, Kent left a faculty position at Yale to join the Research and Analysis Branch of the newly created Coordinator of Information (COI) in 1941. The COI became the Office of Strategic Services (OSS). The OSS became the Central Intelligence Agency (CIA). By the time Kent retired from the CIA in 1967, he had profoundly shaped how the American intelligence community does what it calls intelligence analysis—the methodical examination of the information collected by spies and surveillance to figure out what it means, and what will happen next. The key word in Kent’s work is estimate. As Kent wrote, “estimating is what you do when you do not know.”9 And as Kent emphasized over and over, we never truly know what will happen next. Hence forecasting is all about estimating the likelihood of something happening, which Kent and his colleagues did for many years at the Office of National Estimates—an obscure but extraordinarily influential bureau whose job was to draw on all information available to the CIA, synthesize it, and forecast anything and everything that might help the top officeholders in the US government decide what to do next. Kent and his colleagues were far from perfect. Most notoriously, they published a 1962 estimate that argued the Soviets would not be so foolish as to deploy offensive missiles to Cuba, when, in fact, they already had. But for the most part, their estimates were well regarded because Kent upheld high standards of analytical rigor. ([Location 840](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=840))
## New highlights added April 1, 2022 at 5:53 PM
- People liked clarity and precision in principle but when it came time to make clear and precise forecasts they weren’t so keen on numbers. Some said it felt unnatural or awkward, which it does when you’ve spent a lifetime using vague language, but that’s a weak argument against change. Others expressed an aesthetic revulsion. Language has its own poetry, they felt, and it’s tacky to talk explicitly about numerical odds. ([Location 890](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=890))
- vague thoughts are easily expressed with vague language but when forecasters are forced to translate terms like “serious possibility” into numbers, they have to think carefully about how they are thinking, a process known as metacognition. ([Location 900](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=900))
- Forecasts must have clearly defined terms and timelines. They must use numbers. And one more thing is essential: we must have lots of forecasts. ([Location 939](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=939))
- The many forecasts required for calibration calculations make it impractical to judge forecasts about rare events, and even with common events it means we must be patient data collectors—and cautious data interpreters. ([Location 954](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=954))
- Important as calibration is, it’s not the whole story because “perfect calibration” isn’t what we think of when we imagine perfect forecasting accuracy. Perfection is godlike omniscience. It’s saying “this will happen” and it does, or “this won’t happen” and it doesn’t. The technical term for this is “resolution.” ([Location 958](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=958))
- The math behind this system was developed by Glenn W. Brier in 1950, hence results are called Brier scores. In effect, Brier scores measure the distance between what you forecast and what actually happened. So Brier scores are like golf scores: lower is better. Perfection is 0. A hedged fifty-fifty call, or random guessing in the aggregate, will produce a Brier score of 0.5. A forecast that is wrong to the greatest possible extent—saying there is a 100% chance that something will happen and it doesn’t, every time—scores a disastrous 2.0, as far from The Truth as it is possible to get. ([Location 977](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=977))
- One group tended to organize their thinking around Big Ideas, although they didn’t agree on which Big Ideas were true or false. Some were environmental doomsters (“We’re running out of everything”); others were cornucopian boomsters (“We can find cost-effective substitutes for everything”). Some were socialists (who favored state control of the commanding heights of the economy); others were free-market fundamentalists (who wanted to minimize regulation). As ideologically diverse as they were, they were united by the fact that their thinking was so ideological. They sought to squeeze complex problems into the preferred cause-effect templates and treated what did not fit as irrelevant distractions. Allergic to wishy-washy answers, they kept pushing their analyses to the limit (and then some), using terms like “furthermore” and “moreover” while piling up reasons why they were right and others wrong. As a result, they were unusually confident and likelier to declare things “impossible” or “certain.” Committed to their conclusions, they were reluctant to change their minds even when their predictions clearly failed. They would tell us, “Just wait.” The other group consisted of more pragmatic experts who drew on many analytical tools, with the choice of tool hinging on the particular problem they faced. These experts gathered as much information from as many sources as they could. When thinking, they often shifted mental gears, sprinkling their speech with transition markers such as “however,” “but,” “although,” and “on the other hand.” They talked about possibilities and probabilities, not certainties. And while no one likes to say “I was wrong,” these experts more readily admitted it and changed their minds. ([Location 1037](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1037))
- Foxes beat hedgehogs. And the foxes didn’t just win by acting like chickens, playing it safe with 60% and 70% forecasts where hedgehogs boldly went with 90% and 100%. Foxes beat hedgehogs on both calibration and resolution. Foxes had real foresight. Hedgehogs didn’t. ([Location 1055](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1055))
- How well aggregation works depends on what you are aggregating. Aggregating the judgments of many people who know nothing produces a lot of nothing. Aggregating the judgments of people who know a little is better, and if there are enough of them, it can produce impressive results, but aggregating the judgments of an equal number of people who know lots about lots of different things is most effective because the collective pool of information becomes much bigger. Aggregations of aggregations can also yield impressive results. ([Location 1122](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1122))
- Now look at how foxes approach forecasting. They deploy not one analytical idea but many and seek out information not from one source but many. Then they synthesize it all into a single conclusion. In a word, they aggregate. They may be individuals working alone, but what they do is, in principle, no different from what Galton’s crowd did. They integrate perspectives and the information contained within them. The only real difference is that the process occurs within one skull. ([Location 1131](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1131))
- A fox with the bulging eyes of a dragonfly is an ugly mixed metaphor but it captures a key reason why the foresight of foxes is superior to that of hedgehogs with their green-tinted glasses. Foxes aggregate perspectives. ([Location 1177](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1177))
- No model captures the richness of human nature. Models are supposed to simplify things, which is why even the best are flawed. But they’re necessary. Our minds are full of models. We couldn’t function without them. And we often function pretty well because some of our models are decent approximations of reality. “All models are wrong,” the statistician George Box observed, “but some are useful.” The fox/hedgehog model is a starting point, not the end. ([Location 1213](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1213))
- In 2006 the Intelligence Advanced Research Projects Activity (IARPA) was created. Its mission is to fund cutting-edge research with the potential to make the intelligence community smarter and more effective. ([Location 1293](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1293))
- In 2008 the Office of the Director of National Intelligence—which sits atop the entire network of sixteen intelligence agencies—asked the National Research Council to form a committee. The task was to synthesize research on good judgment and help the IC put that research to good use. By Washington’s standards, it was a bold (or rash) thing to do. It’s not every day that a bureaucracy pays one of the world’s most respected scientific institutions to produce an objective report that might conclude that the bureaucracy is clueless. ([Location 1297](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1297))
- Even the $50 billion question—How accurate are the forecasts of intelligence analysts?—can’t be answered. Of course, some think they know. Senior officials may claim that the IC is right 80% or 90% of the time. But these are just guesses. Like nineteenth-century physicians who were sure that their treatments cured patients 80% or 90% of the time, they may be right, or close to right, or very wrong. Absent accuracy metrics, there is no meaningful way to hold intelligence analysts accountable for accuracy. ([Location 1312](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1312))
- IARPA’s plan was to create tournament-style incentives for top researchers to generate accurate probability estimates for Goldilocks-zone questions. ([Location 1345](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1345))
## New highlights added April 5, 2022 at 9:09 AM
- Thanks to IARPA, we now know a few hundred ordinary people and some simple math can not only compete with professionals supported by a multibillion-dollar apparatus but also beat them. ([Location 1381](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1381))
- The psychologist Ellen Langer has shown how poorly we grasp randomness in a series of experiments. ([Location 1464](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1464))
- Are superforecasters better simply because they are more knowledgeable and intelligent than others? That would be flattering for them but deflating for the rest of us. Knowledge is something we can all increase, but only slowly. People who haven’t stayed mentally active have little hope of catching up to lifelong learners. Intelligence feels like an even more daunting obstacle. ([Location 1600](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1600))
- Ultimately, it’s not the crunching power that counts. It’s how you use it. ([Location 1645](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1645))
- What Fermi understood is that by breaking down the question, we can better separate the knowable and the unknowable. So guessing—pulling a number out of the black box—isn’t eliminated. But we have brought our guessing process out into the light of day where we can inspect it. And the net result tends to be a more accurate estimate than whatever number happened to pop out of the black box when we first read the question. ([Location 1663](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1663))
- So a forecaster who starts by diving into the inside view risks being swayed by a number that may have little or no meaning. But if she starts with the outside view, her analysis will begin with an anchor that is meaningful. And a better anchor is a distinct advantage. ([Location 1797](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1797))
- Coming up with an outside view, an inside view, and a synthesis of the two isn’t the end. It’s a good beginning. Superforecasters constantly look for other views they can synthesize into their own. ([Location 1836](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1836))
- Forget the old advice to think twice. Superforecasters often think thrice—and sometimes they are just warming up to do a deeper-dive analysis. ([Location 1872](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1872))
- A brilliant puzzle solver may have the raw material for forecasting, but if he doesn’t also have an appetite for questioning basic, emotionally charged beliefs he will often be at a disadvantage relative to a less intelligent person who has a greater capacity for self-critical thinking. It’s not the raw crunching power you have that matters most. It’s what you do with it. ([Location 1883](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1883))
- Active open-mindedness (AOM) is a concept coined by the psychologist Jonathan Baron, who has an office next to mine at the University of Pennsylvania. ([Location 1891](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1891))
- For superforecasters, beliefs are hypotheses to be tested, not treasures to be guarded. It would be facile to reduce superforecasting to a bumper-sticker slogan, but if I had to, that would be it. ([Location 1900](https://readwise.io/to_kindle?action=open&asin=B00Y78X7HY&location=1900))
